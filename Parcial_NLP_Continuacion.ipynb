{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec11a646-d678-4706-a0ee-aed92cec7293",
   "metadata": {},
   "source": [
    "### Pregunta 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c7e3b-c2a9-41f6-b63a-ba5df90e6d80",
   "metadata": {},
   "source": [
    "#### Continuación **agregando parte 1, en una clase**\n",
    "\n",
    "Se agregó las funciones de la parte 1 en una clase llamada Ngrama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cf51daf-0f2c-44ae-967c-de25359595d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['all models are wrong','a model is wrong','some models are useful']\n",
    "vocab = ['<s>','</s>','a','all','are','model','models','some','useful','wrong']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92684639-1a02-4f93-a5f0-e0b57e1c8360",
   "metadata": {},
   "source": [
    "#### a) Calcular todas las probabilidades de los bigramas sin suavisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "507249fd-dc84-49c8-a7e7-20af7e3b3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Ngrama:\n",
    "    def __init__(self, corpus , vocab ):\n",
    "        # Inicializamos el vocabulario\n",
    "        self.vocab = vocab\n",
    "        # Tokenizamos el corpus de acuerdo a la naturaleza del corpus\n",
    "        if isinstance(corpus,list):\n",
    "            self.corpus_tokenized = self.preprocesar_list_corpus(corpus)\n",
    "        elif isinstance(corpus,str):\n",
    "            corpus_tokenized = self.tokenized_text(corpus)\n",
    "            self.corpus_tokenized = self.preprocesar_list_corpus(corpus_tokenized)\n",
    "        else:\n",
    "            print('El corpus debe ser un texto o una lista de oraciones')\n",
    "\n",
    "        # Definimos los unigramas, bigramas del corpus y sus frecuencias\n",
    "        self.unigrams =  self.get_freq_ngrams(self.corpus_tokenized,1)\n",
    "        self.bigrams  =  self.get_freq_ngrams(self.corpus_tokenized,2)\n",
    "\n",
    "        # Calculamos el total de bigramas\n",
    "        self.total_bigrams = self.get_freq_t_bigrams(self.bigrams)\n",
    "\n",
    "    def get_freq_t_bigrams(self,bigrams:dict)->dict:\n",
    "        t_bigram_freq = {}\n",
    "        for word1 in vocab:\n",
    "            for word2 in vocab:\n",
    "                bigram = (word1,word2)\n",
    "                t_bigram_freq[bigram] = bigrams.get((word1,word2),0)\n",
    "        return t_bigram_freq   \n",
    "\n",
    "    def get_freq_ngrams(self,corpus_tokenized:list, n_type: int)->dict:\n",
    "        ngrams_freq = {}\n",
    "        n = len(corpus_tokenized)\n",
    "        for i in range(n-n_type+1):\n",
    "            ngram = tuple(corpus_tokenized[i:i+n_type])\n",
    "            if ngram not in ngrams_freq:\n",
    "                ngrams_freq[ngram]=1\n",
    "            else:\n",
    "                ngrams_freq[ngram]+=1\n",
    "        return ngrams_freq\n",
    "\n",
    "    def preprocesar_list_corpus(self,corpus:list):\n",
    "        new_sentence = ['<s>']\n",
    "        for sentence in corpus :\n",
    "            # Preprocesamos una oracion en token de palabras\n",
    "            sentence_tokenized = self.tokenized_sentence(sentence)            \n",
    "            # Agregamos el tag de final de oracion\n",
    "            new_sentence += (sentence_tokenized + ['</s>']) \n",
    "        return new_sentence\n",
    "        \n",
    "    def tokenized_sentence(self,sentence:str)->list:\n",
    "        pattern = re.compile(r'\\b\\w+\\b')\n",
    "        words = pattern.findall(sentence)\n",
    "        \n",
    "        # Verificamos si cada palabra esta en el vocabulario\n",
    "        tokenized_words = [word.lower() if word in self.vocab else '<unk>' for word in words]\n",
    "        \n",
    "        return tokenized_words\n",
    "\n",
    "    def tokenized_text(self,text:str)->list:\n",
    "        return re.split(r'(?<=[.!?])\\s+',text)\n",
    "\n",
    "    def get_prob_bigram(self,bigrams:dict,unigrams:dict):\n",
    "        prob_bigrams = {}\n",
    "        for bigram,freq in bigrams.items():\n",
    "            prob_bigrams[bigram] = (freq)/(unigrams[(bigram[0],)])\n",
    "        return prob_bigrams\n",
    "\n",
    "    def get_prob_add_k_bigram(self,bigrams:dict,unigrams:dict,k:float):\n",
    "        # Tamaño del vocabulario\n",
    "        V = len(vocab)        \n",
    "        # Cálculo de las probabilidades suavizadas\n",
    "        add_k_probabilities = {}\n",
    "        for (w1,w2), freq in bigrams.items():\n",
    "            N = unigrams.get((w1,),0)\n",
    "            # Aplicando la ecuación P_Add-k(w_i) = (c_i + k) / (N + kV)\n",
    "            add_k_probabilities[(w1,w2)] = (freq + k) / (N + k * V)\n",
    "            #print(f'({w1},{w2}) = ({freq} + {k}) / ({N} + {k} * {V}) = {(freq + k) / (N + k * V)} ')        \n",
    "        return add_k_probabilities\n",
    "        \n",
    "\n",
    "    def get_prob_stupid_backoff_bigram(self, bigrams: dict, unigrams: dict, lambda_factor: float):\n",
    "        \"\"\"\n",
    "        Calcula las probabilidades usando Stupid Backoff.\n",
    "        Si el bigrama no se ha visto, retrocede al unigram y multiplica por lambda.\n",
    "        Nota: Para bigramas el backoff y stupid backoff sale lo mismo.\n",
    "        \"\"\"\n",
    "        stupid_backoff_probabilities = {}\n",
    "        V = len(self.vocab)  # Tamaño del vocabulario\n",
    "\n",
    "        for bigram, freq in self.total_bigrams.items():\n",
    "            w1, w2 = bigram\n",
    "            if bigram in bigrams and bigrams[bigram] > 0:\n",
    "                # Si el bigrama existe, calcular la probabilidad normal\n",
    "                stupid_backoff_probabilities[bigram] = bigrams[bigram] / unigrams[(w1,)]\n",
    "            else:\n",
    "                # Retrocedemos al unigram y multiplicamos por lambda\n",
    "                stupid_backoff_probabilities[bigram] = lambda_factor * (unigrams.get((w2,), 0) / sum(unigrams.values()))\n",
    "\n",
    "        return stupid_backoff_probabilities\n",
    "    ########################################################### PARTE 2 ##########################################    \n",
    "    def calculate_N_r(self, ngram_counts: dict):\n",
    "        \"\"\"\n",
    "        Calcula N_r, donde r es la frecuencia y N_r es el número de n-gramas\n",
    "        que ocurren exactamente r veces.\n",
    "        \"\"\"\n",
    "        N_r = {}\n",
    "        for count in ngram_counts.values():\n",
    "            if count not in N_r:\n",
    "                N_r[count] = 1\n",
    "            else:\n",
    "                N_r[count] += 1\n",
    "\n",
    "        # Definir N_0 = 1 como el número de elementos no observados\n",
    "        N_r[0] = 1\n",
    "        return N_r\n",
    "\n",
    "    def good_turing_smoothing(self, ngram_counts: dict, N_r: dict) -> dict:\n",
    "        \n",
    "        adjusted_counts = {}\n",
    "\n",
    "        # Para cada n-grama en los conteos\n",
    "        for ngram, count in ngram_counts.items():\n",
    "            r = count\n",
    "            if r + 1 in N_r and r in N_r:\n",
    "                # Aplicar la formula Good-Turing: c* = (r+1) * (N_{r+1} / N_r)\n",
    "                adjusted_count = (r + 1) * (N_r[r + 1] / N_r[r])\n",
    "            else:\n",
    "                # Para valores grandes de r o cuando no hay N_{r+1}, dejamos el valor como esta\n",
    "                adjusted_count = r\n",
    "\n",
    "            adjusted_counts[ngram] = adjusted_count\n",
    "\n",
    "        return adjusted_counts\n",
    "\n",
    "    def calculate_good_turing_probabilities(self, adjusted_counts: dict):\n",
    "        \n",
    "        total_adjusted_count = len(adjusted_counts)\n",
    "        probabilities = {ngram: count / total_adjusted_count for ngram, count in adjusted_counts.items()}\n",
    "        return probabilities\n",
    "        \n",
    "    def apply_good_turing(self):\n",
    "        \n",
    "        # Calculamos N_r a partir de los conteos de bigramas\n",
    "        N_r = self.calculate_N_r(self.bigrams)\n",
    "\n",
    "        # Ajustamos los conteos con Good-Turing\n",
    "        adjusted_bigrams = self.good_turing_smoothing(self.bigrams, N_r)\n",
    "\n",
    "        # Calculamos las probabilidades ajustadas\n",
    "        good_turing_probabilities = self.calculate_good_turing_probabilities(adjusted_bigrams)\n",
    "        \n",
    "        return good_turing_probabilities\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bc6c2a1-8ab1-4316-b1d7-26715b37e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = Ngrama(corpus,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2733b09d-2f0f-41d0-ba15-f68bb5af1eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>',): 1,\n",
       " ('all',): 1,\n",
       " ('models',): 2,\n",
       " ('are',): 2,\n",
       " ('wrong',): 2,\n",
       " ('</s>',): 3,\n",
       " ('a',): 1,\n",
       " ('model',): 1,\n",
       " ('<unk>',): 1,\n",
       " ('some',): 1,\n",
       " ('useful',): 1}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "608a65ba-0f39-4482-aaa2-4572cf9940fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>', 'all'): 1,\n",
       " ('all', 'models'): 1,\n",
       " ('models', 'are'): 2,\n",
       " ('are', 'wrong'): 1,\n",
       " ('wrong', '</s>'): 2,\n",
       " ('</s>', 'a'): 1,\n",
       " ('a', 'model'): 1,\n",
       " ('model', '<unk>'): 1,\n",
       " ('<unk>', 'wrong'): 1,\n",
       " ('</s>', 'some'): 1,\n",
       " ('some', 'models'): 1,\n",
       " ('are', 'useful'): 1,\n",
       " ('useful', '</s>'): 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "762a81e2-1901-4428-8834-07bba35d84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_freq = ml.get_freq_t_bigrams(ml.bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408a321-34f2-439e-9104-acbdd0c43d94",
   "metadata": {},
   "source": [
    "## Probabilidades sin Suavizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00960c72-0ffc-4939-8e10-996cf3dc383a",
   "metadata": {},
   "source": [
    "prob_bigramas = ml.get_prob_bigram(total_freq,ml.unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b04d823-3829-4fe4-a3ec-66a324a20fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 - Probabilidades sin suavizado\n",
      "('<s>', 'all'): 1.0\n",
      "('a', 'model'): 1.0\n",
      "('all', 'models'): 1.0\n",
      "('models', 'are'): 1.0\n",
      "('some', 'models'): 1.0\n",
      "('useful', '</s>'): 1.0\n",
      "('wrong', '</s>'): 1.0\n",
      "('are', 'useful'): 0.5\n",
      "('are', 'wrong'): 0.5\n",
      "('</s>', 'a'): 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "prob_bigramas = ml.get_prob_bigram(total_freq,ml.unigrams)\n",
    "prob_ord = sorted( prob_bigramas.items() , key = lambda x: x[1]  , reverse = True)[:10]\n",
    "print('Top 10 - Probabilidades sin suavizado')\n",
    "for (bigram,prob) in prob_ord:\n",
    "    print(f'{bigram}: {prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f694d52-0c61-4447-b38f-be5ea35b0821",
   "metadata": {},
   "source": [
    "## Probabilidades con Suavizado add-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ede99c3b-4c4a-406a-a234-1294665b7c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 - Probabilidades con suavizado add-one\n",
      "('models', 'are'): 0.25\n",
      "('wrong', '</s>'): 0.25\n",
      "('<s>', 'all'): 0.18181818181818182\n",
      "('a', 'model'): 0.18181818181818182\n",
      "('all', 'models'): 0.18181818181818182\n",
      "('some', 'models'): 0.18181818181818182\n",
      "('useful', '</s>'): 0.18181818181818182\n",
      "('are', 'useful'): 0.16666666666666666\n",
      "('are', 'wrong'): 0.16666666666666666\n",
      "('</s>', 'a'): 0.15384615384615385\n"
     ]
    }
   ],
   "source": [
    "add_k_probabilities =ml.get_prob_add_k_bigram(total_freq,ml.unigrams,k=1)\n",
    "\n",
    "prob_ord = sorted( add_k_probabilities.items() , key = lambda x: x[1]  , reverse = True)[:10]\n",
    "print('Top 10 - Probabilidades con suavizado add-one')\n",
    "for (bigram,prob) in prob_ord:\n",
    "    print(f'{bigram}: {prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c9106b1-b139-4ae4-a7ee-cb5e82612179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('models', '<s>') : 0.08333333333333333\n",
      "('models', '</s>') : 0.08333333333333333\n",
      "('models', 'a') : 0.08333333333333333\n",
      "('models', 'all') : 0.08333333333333333\n",
      "('models', 'are') : 0.25\n",
      "('models', 'model') : 0.08333333333333333\n",
      "('models', 'models') : 0.08333333333333333\n",
      "('models', 'some') : 0.08333333333333333\n",
      "('models', 'useful') : 0.08333333333333333\n",
      "('models', 'wrong') : 0.08333333333333333\n",
      "suma probabilidades: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Veamos un ejemplo de los posibles bigramas del vocabulario y sus probabilidades\n",
    "# Para el unigram : 'models' \n",
    "suma = 0\n",
    "for bigram,p in add_k_probabilities.items():\n",
    "    if bigram[0] == 'models':\n",
    "        print(f'{bigram} : {p}')\n",
    "        suma+=p\n",
    "print(f'suma probabilidades: {suma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cfae01-6a06-40df-95b0-751d36cbd420",
   "metadata": {},
   "source": [
    "### Bigrama no visto : **( a , models )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef95e555-2f02-42fe-bbc8-5aa28f65e980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'models') : 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "# Para el Bigrama a models\n",
    "bigrama = ('a','models')\n",
    "for bigram,p in add_k_probabilities.items():\n",
    "    if bigram == bigrama:\n",
    "        print(f'{bigram} : {p}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0122d-c56a-4918-8879-9163338f098d",
   "metadata": {},
   "source": [
    "## Probabilidades sin Suavizado add-k = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfc8a8f0-e0c0-474c-a3f2-1c45d67ce7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 - Probabilidades con suavizado add-k = 0.05\n",
      "('models', 'are'): 0.82\n",
      "('wrong', '</s>'): 0.82\n",
      "('<s>', 'all'): 0.7000000000000001\n",
      "('a', 'model'): 0.7000000000000001\n",
      "('all', 'models'): 0.7000000000000001\n",
      "('some', 'models'): 0.7000000000000001\n",
      "('useful', '</s>'): 0.7000000000000001\n",
      "('are', 'useful'): 0.42000000000000004\n",
      "('are', 'wrong'): 0.42000000000000004\n",
      "('</s>', 'a'): 0.3\n"
     ]
    }
   ],
   "source": [
    "add_k_probabilities_1 =ml.get_prob_add_k_bigram(total_freq,ml.unigrams,k=0.05)\n",
    "\n",
    "prob_ord = sorted( add_k_probabilities_1.items() , key = lambda x: x[1]  , reverse = True)[:10]\n",
    "print('Top 10 - Probabilidades con suavizado add-k = 0.05')\n",
    "for (bigram,prob) in prob_ord:\n",
    "    print(f'{bigram}: {prob}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c013e62-6689-434b-9a0f-0a0a8e0a9a7e",
   "metadata": {},
   "source": [
    "Vemos que las probabilidades se han reducido, porque se ha suavizado para los bigramas que no aparecen en el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c32f9574-07e6-405a-8d15-b53c07be92dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('models', '<s>') : 0.02\n",
      "('models', '</s>') : 0.02\n",
      "('models', 'a') : 0.02\n",
      "('models', 'all') : 0.02\n",
      "('models', 'are') : 0.82\n",
      "('models', 'model') : 0.02\n",
      "('models', 'models') : 0.02\n",
      "('models', 'some') : 0.02\n",
      "('models', 'useful') : 0.02\n",
      "('models', 'wrong') : 0.02\n",
      "suma probabilidades: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Veamos un ejemplo de los posibles bigramas del vocabulario y sus probabilidades\n",
    "# Para el unigram : 'models' \n",
    "suma = 0\n",
    "for bigram,p in add_k_probabilities_1.items():\n",
    "    if bigram[0] == 'models':\n",
    "        print(f'{bigram} : {p}')\n",
    "        suma+=p\n",
    "print(f'suma probabilidades: {suma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae470f-c05d-4e61-9927-105d82976105",
   "metadata": {},
   "source": [
    "### Bigrama no visto : **( a , models )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1648ebb4-fa3d-4d2e-b267-f2d17ca8cb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'models') : 0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Para el Bigrama a models\n",
    "bigrama = ('a','models')\n",
    "for bigram,p in add_k_probabilities_1.items():\n",
    "    if bigram == bigrama:\n",
    "        print(f'{bigram} : {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b4269-be92-452f-b7d9-98732ff1be59",
   "metadata": {},
   "source": [
    "## Probabilidades sin Suavizado add-k = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f12a526-6a12-4ead-b78a-a92ca5af353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 - Probabilidades con suavizado add-k = 0.15\n",
      "('models', 'are'): 0.6142857142857142\n",
      "('wrong', '</s>'): 0.6142857142857142\n",
      "('<s>', 'all'): 0.45999999999999996\n",
      "('a', 'model'): 0.45999999999999996\n",
      "('all', 'models'): 0.45999999999999996\n",
      "('some', 'models'): 0.45999999999999996\n",
      "('useful', '</s>'): 0.45999999999999996\n",
      "('are', 'useful'): 0.32857142857142857\n",
      "('are', 'wrong'): 0.32857142857142857\n",
      "('</s>', 'a'): 0.25555555555555554\n"
     ]
    }
   ],
   "source": [
    "add_k_probabilities_2 =ml.get_prob_add_k_bigram(total_freq,ml.unigrams,k=0.15)\n",
    "\n",
    "prob_ord = sorted( add_k_probabilities_2.items() , key = lambda x: x[1]  , reverse = True)[:10]\n",
    "print('Top 10 - Probabilidades con suavizado add-k = 0.15')\n",
    "for (bigram,prob) in prob_ord:\n",
    "    print(f'{bigram}: {prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f868cad-379b-4c62-a259-9cf8a35dc4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('models', '<s>') : 0.04285714285714286\n",
      "('models', '</s>') : 0.04285714285714286\n",
      "('models', 'a') : 0.04285714285714286\n",
      "('models', 'all') : 0.04285714285714286\n",
      "('models', 'are') : 0.6142857142857142\n",
      "('models', 'model') : 0.04285714285714286\n",
      "('models', 'models') : 0.04285714285714286\n",
      "('models', 'some') : 0.04285714285714286\n",
      "('models', 'useful') : 0.04285714285714286\n",
      "('models', 'wrong') : 0.04285714285714286\n",
      "suma probabilidades: 0.9999999999999997\n"
     ]
    }
   ],
   "source": [
    "# Veamos un ejemplo de los posibles bigramas del vocabulario y sus probabilidades\n",
    "# Para el unigram : 'models' \n",
    "suma = 0\n",
    "for bigram,p in add_k_probabilities_2.items():\n",
    "    if bigram[0] == 'models':\n",
    "        print(f'{bigram} : {p}')\n",
    "        suma+=p\n",
    "print(f'suma probabilidades: {suma}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535c327-eeec-4022-a043-1f5768f862c0",
   "metadata": {},
   "source": [
    "### Bigrama no visto : **( a , models )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2d89d6d1-107b-4e06-921c-4f8a472bd17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'models') : 0.06\n"
     ]
    }
   ],
   "source": [
    "# Para el Bigrama a models\n",
    "bigrama = ('a','models')\n",
    "for bigram,p in add_k_probabilities_2.items():\n",
    "    if bigram == bigrama:\n",
    "        print(f'{bigram} : {p}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61da248-aa25-457a-8cd6-6719ffeee69f",
   "metadata": {},
   "source": [
    "## Backoff y stupid-backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "897dca21-e533-458d-a30b-f8ec147a65e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('models', '<s>'): 0.025\n",
      "('models', '</s>'): 0.07500000000000001\n",
      "('models', 'a'): 0.025\n",
      "('models', 'all'): 0.025\n",
      "('models', 'are'): 1.0\n",
      "('models', 'model'): 0.025\n",
      "('models', 'models'): 0.05\n",
      "('models', 'some'): 0.025\n",
      "('models', 'useful'): 0.025\n",
      "('models', 'wrong'): 0.05\n",
      "Suma de probabilidades (Stupid Backoff) para 'models': 1.3249999999999997\n"
     ]
    }
   ],
   "source": [
    "# Probamos la funcion Stupid Backoff con lambda = 0.4\n",
    "lambda_factor = 0.4\n",
    "stupid_backoff_probabilities = ml.get_prob_stupid_backoff_bigram(total_freq, ml.unigrams, lambda_factor)\n",
    "\n",
    "# Verificamos si las probabilidades suman 1 para el unigram 'models'\n",
    "sum_prob_stupid_backoff = 0\n",
    "for bigram, prob in stupid_backoff_probabilities.items():\n",
    "    if bigram[0] == 'models':\n",
    "        print(f\"{bigram}: {prob}\")\n",
    "        sum_prob_stupid_backoff += prob\n",
    "\n",
    "print(f\"Suma de probabilidades (Stupid Backoff) para 'models': {sum_prob_stupid_backoff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf14fc1-ce88-4d81-9963-25e1d5a0871a",
   "metadata": {},
   "source": [
    "# PARTE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a64c204-b6b3-40b8-ab86-d63c928485e9",
   "metadata": {},
   "source": [
    "### (e) - Cálculo de r , Nr , N0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a4019d62-e7e7-45ac-b68a-7226361959bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>',): 1,\n",
       " ('all',): 1,\n",
       " ('models',): 2,\n",
       " ('are',): 2,\n",
       " ('wrong',): 2,\n",
       " ('</s>',): 3,\n",
       " ('a',): 1,\n",
       " ('model',): 1,\n",
       " ('<unk>',): 1,\n",
       " ('some',): 1,\n",
       " ('useful',): 1}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unigramas de la parte 1\n",
    "ml.unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2800f25-4d1f-409c-9a82-b81589211ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr para los unigramas: {1: 7, 2: 3, 3: 1, 0: 1}\n",
      "Valor de N_0: 1\n"
     ]
    }
   ],
   "source": [
    "# Aplicar el cálculo de N_r para los unigramas\n",
    "Nr_unigrams = ml.calculate_N_r(ml.unigrams)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Nr para los unigramas:\", Nr_unigrams)\n",
    "print(\"Valor de N_0:\", Nr_unigrams.get(0, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a249f-1fc7-4a54-af75-95f52570ad99",
   "metadata": {},
   "source": [
    "### (f) Calculo de cr para r < 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43953e22-f130-4f9a-99e9-b9df5cdfc883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>',): 0.8571428571428571,\n",
       " ('all',): 0.8571428571428571,\n",
       " ('models',): 1.0,\n",
       " ('are',): 1.0,\n",
       " ('wrong',): 1.0,\n",
       " ('</s>',): 3,\n",
       " ('a',): 0.8571428571428571,\n",
       " ('model',): 0.8571428571428571,\n",
       " ('<unk>',): 0.8571428571428571,\n",
       " ('some',): 0.8571428571428571,\n",
       " ('useful',): 0.8571428571428571}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicamos suavizado Good-Turing a los unigramas\n",
    "adjusted_unigrams = ml.good_turing_smoothing(ml.unigrams, Nr_unigrams)\n",
    "adjusted_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4dd3cafb-d295-4ccc-a599-b9491562a017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>',): 0.07792207792207792,\n",
       " ('all',): 0.07792207792207792,\n",
       " ('models',): 0.09090909090909091,\n",
       " ('are',): 0.09090909090909091,\n",
       " ('wrong',): 0.09090909090909091,\n",
       " ('</s>',): 0.2727272727272727,\n",
       " ('a',): 0.07792207792207792,\n",
       " ('model',): 0.07792207792207792,\n",
       " ('<unk>',): 0.07792207792207792,\n",
       " ('some',): 0.07792207792207792,\n",
       " ('useful',): 0.07792207792207792}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos probabilidades ajustadas\n",
    "good_turing_probabilities = ml.calculate_good_turing_probabilities(adjusted_unigrams)\n",
    "good_turing_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2fa96b9c-7bcb-41b7-b807-531cf00aaf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades ajustadas Good-Turing (r < 3):\n",
      "('<s>',): 0.07792207792207792\n",
      "('all',): 0.07792207792207792\n",
      "('models',): 0.09090909090909091\n",
      "('are',): 0.09090909090909091\n",
      "('wrong',): 0.09090909090909091\n",
      "('a',): 0.07792207792207792\n",
      "('model',): 0.07792207792207792\n",
      "('<unk>',): 0.07792207792207792\n",
      "('some',): 0.07792207792207792\n",
      "('useful',): 0.07792207792207792\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los resultados para los unigramas con r < 3\n",
    "print(\"Probabilidades ajustadas Good-Turing (r < 3):\")\n",
    "for unigram, prob in good_turing_probabilities.items():\n",
    "    count = ml.unigrams[unigram]\n",
    "    if count < 3:\n",
    "        print(f\"{unigram}: {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f2376-40b9-41bf-a05e-427ede205e9f",
   "metadata": {},
   "source": [
    "### (g) Cálculo de la probabilidad mediante MLE para r máximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "815a84e0-925a-4df4-8b32-eeb73c3fcc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_max = 3\n",
      "Probabilidades MLE para r máximo (3):\n",
      "('</s>',): 0.1875\n"
     ]
    }
   ],
   "source": [
    "# MLE: si N_{r+1} = 0, calculamos la probabilidad P(w | #w = r)\n",
    "r_max = max(Nr_unigrams.keys())\n",
    "print(f'r_max = {r_max}')\n",
    "\n",
    "# Calculamos probabilidad con MLE\n",
    "def calculate_MLE(ngram_counts):\n",
    "    total_count = sum(ngram_counts.values())\n",
    "    probabilities = {ngram: count / total_count for ngram, count in ngram_counts.items()}\n",
    "    return probabilities\n",
    "\n",
    "# Probabilidades con MLE para el valor máximo de r\n",
    "mle_probabilities = calculate_MLE(ml.unigrams)\n",
    "\n",
    "# Mostramos las probabilidades MLE\n",
    "print(f\"Probabilidades MLE para r máximo ({r_max}):\")\n",
    "for unigram, prob in mle_probabilities.items():\n",
    "    count = ml.unigrams[unigram]\n",
    "    if count == r_max:\n",
    "        print(f\"{unigram}: {prob}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9586b-65d6-4a8d-bb4c-c26200159fa2",
   "metadata": {},
   "source": [
    "### (h) - Normalización de las probabilidades para que sumen 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cbe04b1d-f436-4956-88e4-fd81f005f98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('<s>',): 0.07792207792207792,\n",
       " ('all',): 0.07792207792207792,\n",
       " ('models',): 0.09090909090909091,\n",
       " ('are',): 0.09090909090909091,\n",
       " ('wrong',): 0.09090909090909091,\n",
       " ('</s>',): 0.2727272727272727,\n",
       " ('a',): 0.07792207792207792,\n",
       " ('model',): 0.07792207792207792,\n",
       " ('<unk>',): 0.07792207792207792,\n",
       " ('some',): 0.07792207792207792,\n",
       " ('useful',): 0.07792207792207792}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos que la suma no es 1\n",
    "good_turing_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a206427a-1ad6-41fc-b961-a6d61ca5a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma de probabilidades:  1.090909090909091\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for unigram,p in good_turing_probabilities.items():\n",
    "    s+=p\n",
    "print('Suma de probabilidades: ',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "964ec07b-13f1-4a20-b186-fde68b603147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades normalizadas (Good-Turing):\n",
      "('<s>',): 0.07142857142857142\n",
      "('all',): 0.07142857142857142\n",
      "('models',): 0.08333333333333333\n",
      "('are',): 0.08333333333333333\n",
      "('wrong',): 0.08333333333333333\n",
      "('</s>',): 0.24999999999999994\n",
      "('a',): 0.07142857142857142\n",
      "('model',): 0.07142857142857142\n",
      "('<unk>',): 0.07142857142857142\n",
      "('some',): 0.07142857142857142\n",
      "('useful',): 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "# Normalizar probabilidades para que sumen 1\n",
    "def normalize_probabilities(probabilities):\n",
    "    total_prob = sum(probabilities.values())\n",
    "    normalized_probs = {ngram: prob / total_prob for ngram, prob in probabilities.items()}\n",
    "    return normalized_probs\n",
    "\n",
    "# Normalizamos las probabilidades ajustadas\n",
    "normalized_good_turing_probs = normalize_probabilities(good_turing_probabilities)\n",
    "\n",
    "# Mostrar las probabilidades normalizadas\n",
    "print(\"Probabilidades normalizadas (Good-Turing):\")\n",
    "s=0\n",
    "for bigram, prob in normalized_good_turing_probs.items():\n",
    "    s+=prob\n",
    "    print(f\"{bigram}: {prob}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5928fc71-05a3-44ff-b9d9-c02f880f793c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma de probabilidades: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "print(f'Suma de probabilidades: {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f3c4d-fe18-49ab-b407-d00cea81fd24",
   "metadata": {},
   "source": [
    "### (i) - Ajustar suavemente Nr para grandes valores de r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2045bf4d-63f3-4d49-9882-66853ddc5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades ajustadas Good-Turing con N5 suavizado:\n",
      "('<s>',): 0.07792207792207792\n",
      "('all',): 0.07792207792207792\n",
      "('models',): 0.09090909090909091\n",
      "('are',): 0.09090909090909091\n",
      "('wrong',): 0.09090909090909091\n",
      "('</s>',): 0.2727272727272727\n",
      "('a',): 0.07792207792207792\n",
      "('model',): 0.07792207792207792\n",
      "('<unk>',): 0.07792207792207792\n",
      "('some',): 0.07792207792207792\n",
      "('useful',): 0.07792207792207792\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que N5 no existe \n",
    "def smooth_Nr(Nr, r_value):\n",
    "    Nr[r_value] = Nr.get(r_value-1,1) # Ajustamos N5 = N4 o 1 si no existe N4\n",
    "    return Nr\n",
    "\n",
    "# reemplezamos el N5\n",
    "Nr_smoothed = smooth_Nr(Nr_unigrams, 5)\n",
    "\n",
    "# Aplicamos nuevamente Good-Turing con el ajuste suave\n",
    "adjusted_unigrams_smoothed = ml.good_turing_smoothing(ml.unigrams, Nr_smoothed)\n",
    "\n",
    "# Calculamos las probabilidades ajustadas con Good-Turing y el ajuste de N5\n",
    "good_turing_probabilities_smoothed = ml.calculate_good_turing_probabilities(adjusted_unigrams_smoothed)\n",
    "\n",
    "# Mostramos los resultados con el suavizado\n",
    "print(\"Probabilidades ajustadas Good-Turing con N5 suavizado:\")\n",
    "for unigram, prob in good_turing_probabilities_smoothed.items():\n",
    "    print(f\"{unigram}: {prob}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1c7111-e205-4485-9fdb-45ccf4f66f23",
   "metadata": {},
   "source": [
    "# 2 . Brown Clustering , LSA y Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb9069-3912-4e1a-847c-ad7f16747584",
   "metadata": {},
   "source": [
    "## Corpus : UD_Spanish-AnCora\n",
    "\n",
    "link : https://github.com/UniversalDependencies/UD_Spanish-AnCora/blob/master/es_ancora-ud-train.conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3d4b2bf-e20f-4ad0-b8d7-a05246a59410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: conllu in c:\\users\\computer\\anaconda3\\envs\\nlp\\lib\\site-packages (6.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Instalamos la libreria para la lectura del corpus\n",
    "!pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02a9c293-b78a-43ed-9518-d065f6c22ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conllu import parse\n",
    "\n",
    "def read_conllu(file_path):\n",
    "    with open(file_path,'r',encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    sentences = parse(data)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f41389ca-41ef-4c9a-91d0-1162d9709bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso\n",
    "file_path = \"./es_ancora-ud-train.conllu\"\n",
    "sentences = read_conllu(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a1f7cc7c-e120-4707-8427-c6f9e883d53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conllu.models.TokenList"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "76456b23-c085-4a2d-9429-836e45091de3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las reservas de oro y divisas de Rusia subieron 800 millones de dólares y el 26 de mayo equivalían a 19.100 millones de dólares , informó hoy un comunicado del de el Banco Central . "
     ]
    }
   ],
   "source": [
    "# Mostrar la primera oración\n",
    "for token in sentences[0]:\n",
    "    print(token,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "562567e0-1c59-411c-b3e0-c054b1af3aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar a txt\n",
    "def conllu_to_text(file_input,file_output):\n",
    "    sentences = read_conllu(file_input)\n",
    "    # Extraer solo el texto de cada oración\n",
    "    text_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = [token[\"form\"] for token in sentence]  # Extraer solo la palabra (forma)\n",
    "        text_sentences.append(\" \".join(words))  # Unir las palabras en una oración\n",
    "\n",
    "    with open(file_output, 'w', encoding='utf-8') as f:\n",
    "        for sentence in text_sentences:\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6e579db8-4c05-4c9c-a0f1-9d501bb11492",
   "metadata": {},
   "outputs": [],
   "source": [
    "conllu_to_text('./es_ancora-ud-train.conllu','./es_ancora.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e72c0-8a54-430b-b072-0c156e3f2ecc",
   "metadata": {},
   "source": [
    "## Preprocesamiento: Creación de la clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "37a72004-f8e1-4ece-b28a-0f232e5c6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class Preprocess:\n",
    "    def __init__(self, corpus_path):\n",
    "        # Lectura del corpus\n",
    "        self.corpus = self.read_conllu_txt(corpus_path)\n",
    "        # Tokenización\n",
    "        self.corpus_tokenized = self.tokenized(self.corpus)\n",
    "        # Lematización (o stemming simplificado)\n",
    "        self.corpus_lemmatized = self.lemmatize(self.corpus_tokenized)\n",
    "        # Remover stopwords\n",
    "        self.corpus_cleaned = self.remove_stopwords(self.corpus_lemmatized)\n",
    "        # Filtrado de palabras raras (palabras con baja frecuencia)\n",
    "        self.final_corpus = self.filter_rare_words(self.corpus_cleaned)\n",
    "\n",
    "    def read_conllu_txt(self, file_path: str) -> str:\n",
    "        \"\"\"Leer el archivo con el corpus.\"\"\"\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = f.read()\n",
    "        return data\n",
    "\n",
    "    def tokenized(self, corpus: str) -> list:\n",
    "        \"\"\"Tokenización del corpus. Separa el texto en palabras.\"\"\"\n",
    "        pattern = re.compile(r'\\b\\w+\\b')\n",
    "        return pattern.findall(corpus.lower())  \n",
    "        \n",
    "    def simple_stemmer(self,word):\n",
    "            suffixes = ['ar', 'er', 'ir', 'ndo', 'ado', 'ido', 'mente', 'ción', 'sión']\n",
    "            for suffix in suffixes:\n",
    "                if word.endswith(suffix):\n",
    "                    return word[:-len(suffix)]\n",
    "            return word\n",
    "        \n",
    "    def lemmatize(self, tokens: list) -> list:\n",
    "        \"\"\"Aplicar un lematizador simple o stemming.\n",
    "        \"\"\"        \n",
    "        return [self.simple_stemmer(word) for word in tokens]\n",
    "\n",
    "    def remove_stopwords(self, tokens: list) -> list:\n",
    "        \"\"\"Eliminar palabras sin aporte (stopwords)\"\"\"\n",
    "        stopwords = set([\n",
    "            'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas', 'de', 'del', 'al', 'y', 'o', 'a',\n",
    "            'en', 'con', 'por', 'para', 'que', 'es', 'no', 'si', 'se', 'lo', 'su', 'le', 'mi', 'tu', \n",
    "            'este', 'esta', 'estos', 'estas', 'pero', 'más', 'menos', 'muy', 'también','_', 'ha', 'como', \n",
    "            'sus', 's', 'sobre', 'entre' ,'ya' , 'han', 'ay', 'está', 'me'\n",
    "        ])\n",
    "        return [word for word in tokens if word not in stopwords]\n",
    "\n",
    "    def filter_rare_words(self, tokens: list, min_freq=5) -> list:\n",
    "        \"\"\"Filtrar palabras que aparecen menos de 'min_freq' veces.\"\"\"\n",
    "        # Contar la frecuencia de cada palabra\n",
    "        word_freq = Counter(tokens)\n",
    "        # Filtrar palabras con frecuencia menor o igual a 'min_freq'\n",
    "        return [word for word in tokens if word_freq[word] > min_freq]\n",
    "\n",
    "    def save_preprocessed_corpus(self, output_path):\n",
    "        \"\"\"Guardar el corpus final preprocesado en un archivo.\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            for word in self.final_corpus:\n",
    "                f.write(f\"{word} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3bd9f7e5-fe34-4614-8674-a57df8d1fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Preprocess('./es_ancora.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "00a1ff3b-3bee-438b-bfaa-820b6c0a1466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reservas', 'oro', 'divisas', 'rusia', 'subieron', '800', 'millones', 'dólares', '26', 'mayo', '19', '100', 'millones', 'dólares', 'informó', 'hoy', 'comunic', 'banco', 'central', 'según', 'informe', '19', 'mayo', 'reservas', 'oro', 'divisas', 'banco', 'central', 'eran', '18', '300', 'millones', 'dólares', 'activos', 'divisas', 'pod', 'banco', 'central', 'ministerio', 'finanzas', 'dólares', 'estadounidenses', 'valor', 'depende', 'cambio', 'oficial', 'dól', 'establece', 'banco', 'central', 'reservas', 'oro', 'base', '300', 'dólares', 'estadounidenses', 'cada', 'oro', 'presidente', 'generalitat', 'jordi', 'pujol', 'cree', 'necesario', 'gobierno', 'permisos', 'residencia', 'inmigrantes', 'pod', 'respond', 'falta', 'mano', 'obra', 'cataluña', 'según', 'cálculos', 'departamento', 'trabajo', 'impide', 'cubr', '23', '000', 'empleos', 'diversos', 'sectores', 'pujol', 'necesidad', 'medida', 'legal', 'durante', 'cena', 'organizada', 'anoche', 'patronal', 'pequeña', 'empresa', 'advirtió', 'empresarios', 'sindicatos', 'administraciones']\n"
     ]
    }
   ],
   "source": [
    "print(pre.final_corpus[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ecd92297-9587-4843-9971-27feb664bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el preprocesado\n",
    "pre.save_preprocessed_corpus('./corpus_preprocesado.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900152c9-e428-4122-94d3-0fa04c64873f",
   "metadata": {},
   "source": [
    "# Implementación de Técnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1475b4d8-40cf-43c2-bab9-644ab8162a0e",
   "metadata": {},
   "source": [
    "#### Brown clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "1919fb0d-78d0-44a0-819b-2e036509b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "class BrownClustering:\n",
    "    def __init__(self, path_corpus: str):\n",
    "        # Lectura del corpus \n",
    "        self.path_corpus = path_corpus\n",
    "        self.corpus = self.lectura_corpus(self.path_corpus)\n",
    "        \n",
    "        # Tokenizamos el corpus en palabras (limitamos a las primeras 100 palabras)\n",
    "        self.corpus_tokenized = self.tokenizer(self.corpus)[:100]\n",
    "        \n",
    "        # Inicializamos un vocabulario_freq como los unigramas y sus frecuencias en el corpus\n",
    "        self.vocab_freq = self.get_unigrams(self.corpus_tokenized)\n",
    "        \n",
    "        # Inicializamos el conjunto de clases con su frecuencia\n",
    "        self.c_freq = self.update_class_freq(self.vocab_freq)\n",
    "\n",
    "        # Inicializamos el conjunto de bigramas\n",
    "        self.bigrams = self.get_bigrams(self.corpus_tokenized)\n",
    "\n",
    "        # Inicializamos el bigrama _freq\n",
    "        self.bigrams_freq = self.update_bigrams(self.bigrams, self.vocab_freq)\n",
    "\n",
    "        # Inicializamos el c_n_freq\n",
    "        self.c_n_freq = self.update_c_n_freq(self.bigrams, self.vocab_freq)\n",
    "\n",
    "        # Almacenamos las probabilidades de cada palabra\n",
    "        self.prob_words = self.get_prob_words(self.vocab_freq)\n",
    "\n",
    "    def get_prob_words(self, vocab_freq):\n",
    "        N = sum(freq for freq, _ in vocab_freq.values())  # Calcular la suma de las frecuencias una sola vez\n",
    "        return {word: freq / N for word, [freq, _] in vocab_freq.items()}  \n",
    "\n",
    "\n",
    "    def update_c_n_freq(self, bigrams: dict, mapper: dict) -> dict:\n",
    "        # bigrams : { bigrama : freq }\n",
    "        # mapper -> { word : [ freq , clase_pertenece ] }\n",
    "        c_n_freq = {}\n",
    "        for (w1, w2), freq in bigrams.items():\n",
    "            c1, c2 = mapper[w1][1], mapper[w2][1]\n",
    "            c_n_freq[(c1, c2)] = c_n_freq.get((c1, c2), 0) + freq  # Inicializar o incrementar en una sola línea\n",
    "        return c_n_freq\n",
    "\n",
    "    def update_bigrams(self, bigrams: dict, mapper: dict) -> dict:\n",
    "        # Usar comprensión de diccionario para mayor eficiencia\n",
    "        return {b: [freq, (mapper[b[0]][1], mapper[b[1]][1])] for b, freq in bigrams.items()}  \n",
    "\n",
    "    def get_bigrams(self, corpus: list):\n",
    "        bigrams = {}\n",
    "        for i in range(len(corpus) - 1):\n",
    "            b = (corpus[i], corpus[i + 1])\n",
    "            if b not in bigrams:\n",
    "                bigrams[b] = 1\n",
    "            else:\n",
    "                bigrams[b] += 1\n",
    "        return bigrams\n",
    "\n",
    "    def lectura_corpus(self, path):\n",
    "        with open(path, mode='r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "\n",
    "    def tokenizer(self, corpus: str) -> list:\n",
    "        # Tokenizamos por palabras\n",
    "        pattern = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "        return pattern.findall(corpus)\n",
    "\n",
    "    def get_unigrams(self, corpus: list):\n",
    "        unigrams = {}\n",
    "        cluster = 0\n",
    "        for unigram in corpus:\n",
    "            if unigram not in unigrams:\n",
    "                unigrams[unigram] = [1, cluster]\n",
    "                cluster += 1\n",
    "            else:\n",
    "                unigrams[unigram][0] += 1\n",
    "        return unigrams\n",
    "\n",
    "    def update_class_freq(self, vocab_freq: dict):\n",
    "        # { word : [ freq , clase_pertenece ] }\n",
    "        c_freq = {}\n",
    "        for word, [freq, c] in vocab_freq.items():\n",
    "            if c not in c_freq:\n",
    "                c_freq[c] = freq\n",
    "            else:\n",
    "                c_freq[c] += freq\n",
    "        return c_freq\n",
    "\n",
    "    def get_mapper_fusion(self, mapper: dict, ci: int, cj: int) -> dict:\n",
    "        # Fusionamos el mapper\n",
    "        c_update, c_new = max(ci, cj), min(ci, cj)\n",
    "        for word, [freq, c] in mapper.items():\n",
    "            if c == c_update:\n",
    "                mapper[word] = [freq, c_new]\n",
    "        return mapper\n",
    "\n",
    "    def get_prob_ci(self, new_mapper: dict, ci: int):\n",
    "        p_ci = 0\n",
    "        for w in new_mapper:\n",
    "            if new_mapper[w][1] == ci:\n",
    "                p_ci += self.prob_words[w]\n",
    "        return p_ci\n",
    "\n",
    "    def get_IC(self, new_mapper: dict, new_c_mapper: dict, new_c_b_mapper: dict):\n",
    "        N = sum(new_c_b_mapper.values())  # Total de bigramas\n",
    "    \n",
    "        IC = 0\n",
    "        for ci in new_c_mapper:\n",
    "            for cj in new_c_mapper:\n",
    "                # Probabilidad conjunta P(c_i, c_j)\n",
    "                Pij = new_c_b_mapper.get((ci, cj), 0) / N\n",
    "    \n",
    "                if Pij > 0:  # Evitar log(0)\n",
    "                    # Probabilidades marginales P(c_i) y P(c_j)\n",
    "                    Pi = self.get_prob_ci(new_mapper, ci)\n",
    "                    Pj = self.get_prob_ci(new_mapper, cj)\n",
    "    \n",
    "                    # Cálculo de la información mutua\n",
    "                    IC += Pij * math.log(Pij / (Pi * Pj))\n",
    "    \n",
    "        return IC\n",
    "\n",
    "    def get_words_by_class(self):\n",
    "        # Diccionario para almacenar las palabras agrupadas por clase\n",
    "        words_by_class = {}\n",
    "    \n",
    "        # Recorrer el vocabulario y agrupar las palabras por su clase\n",
    "        for word, [freq, clase] in self.vocab_freq.items():\n",
    "            if clase not in words_by_class:\n",
    "                words_by_class[clase] = []  # Inicializa la lista de palabras para la clase\n",
    "            words_by_class[clase].append(word)\n",
    "    \n",
    "        return words_by_class\n",
    "\n",
    "    def train(self, n_clusters: int, verbose: bool = False):\n",
    "        while len(self.c_freq) > n_clusters:\n",
    "            ic_max = -1\n",
    "            best_combination = None  # Inicializar una variable para almacenar la mejor combinación de clases\n",
    "            n = len(self.c_freq)\n",
    "            for ci in self.c_freq:\n",
    "                for cj in self.c_freq:\n",
    "                    if ci!=cj:\n",
    "                        # Fusionamos el mapper\n",
    "                        new_mapper = self.get_mapper_fusion(self.vocab_freq.copy(), ci, cj)\n",
    "    \n",
    "                        # Actualizamos el c_mapper\n",
    "                        new_c_mapper = self.update_class_freq(new_mapper)\n",
    "    \n",
    "                        # Actualizamos el b_mapper y c_b_mapper\n",
    "                        new_b_mapper = self.update_bigrams(self.bigrams, new_mapper)\n",
    "                        new_c_b_mapper = self.update_c_n_freq(self.bigrams, new_mapper)\n",
    "    \n",
    "                        # Calculamos el I(C)\n",
    "                        ic = self.get_IC(new_mapper, new_c_mapper, new_c_b_mapper)\n",
    "    \n",
    "                        if ic > ic_max:\n",
    "                            ic_max = ic\n",
    "                            best_combination = (new_mapper, new_c_mapper, new_b_mapper, new_c_b_mapper, ci, cj)\n",
    "                        \n",
    "    \n",
    "            # Aplicamos la mejor combinación\n",
    "            self.vocab_freq, self.c_freq, self.bigram_freq, self.c_n_freq, c_i_max, c_j_max = best_combination\n",
    "    \n",
    "            if verbose:\n",
    "                print(f'Fusion de clases: {c_i_max} y {c_j_max}, nuevo IC: {ic_max}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bc = BrownClustering('./corpus_preprocesado.txt')        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5e63e869-5738-4975-b1a6-cd8efc8510c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion de clases: 35 y 70, nuevo IC: 3.8961730916080706\n",
      "Fusion de clases: 39 y 71, nuevo IC: 3.8821701182634256\n",
      "Fusion de clases: 41 y 69, nuevo IC: 3.8681671449187807\n",
      "Fusion de clases: 45 y 62, nuevo IC: 3.8541641715741357\n",
      "Fusion de clases: 44 y 61, nuevo IC: 3.8401611982294908\n",
      "Fusion de clases: 43 y 60, nuevo IC: 3.826158224884846\n",
      "Fusion de clases: 42 y 59, nuevo IC: 3.812155251540201\n",
      "Fusion de clases: 4 y 12, nuevo IC: 3.7981522781955555\n",
      "Fusion de clases: 7 y 13, nuevo IC: 3.78414930485091\n",
      "Fusion de clases: 8 y 22, nuevo IC: 3.7701463315062647\n",
      "Fusion de clases: 11 y 15, nuevo IC: 3.7561433581616193\n",
      "Fusion de clases: 16 y 23, nuevo IC: 3.742140384816974\n",
      "Fusion de clases: 18 y 24, nuevo IC: 3.7281374114723285\n",
      "Fusion de clases: 29 y 46, nuevo IC: 3.714134438127683\n",
      "Fusion de clases: 30 y 47, nuevo IC: 3.700131464783038\n",
      "Fusion de clases: 31 y 48, nuevo IC: 3.6861284914383927\n",
      "Fusion de clases: 32 y 49, nuevo IC: 3.6721255180937473\n",
      "Fusion de clases: 29 y 63, nuevo IC: 3.6528372099636015\n",
      "Fusion de clases: 30 y 64, nuevo IC: 3.6335489018334552\n",
      "Fusion de clases: 31 y 65, nuevo IC: 3.6142605937033094\n",
      "Fusion de clases: 32 y 66, nuevo IC: 3.5949722855731636\n",
      "Fusion de clases: 50 y 67, nuevo IC: 3.580969312228518\n",
      "Fusion de clases: 51 y 68, nuevo IC: 3.5669663388838733\n",
      "Fusion de clases: 27 y 45, nuevo IC: 3.5476780307537275\n",
      "Fusion de clases: 26 y 44, nuevo IC: 3.528389722623581\n",
      "Fusion de clases: 33 y 52, nuevo IC: 3.5038160797079354\n",
      "Fusion de clases: 34 y 53, nuevo IC: 3.4898131063632905\n",
      "Fusion de clases: 14 y 54, nuevo IC: 3.465239463447645\n",
      "Fusion de clases: 40 y 72, nuevo IC: 3.4406658205319993\n",
      "Fusion de clases: 41 y 73, nuevo IC: 3.4213775124018535\n",
      "Fusion de clases: 7 y 21, nuevo IC: 3.396803869486207\n",
      "Fusion de clases: 35 y 55, nuevo IC: 3.3722302265705606\n",
      "Fusion de clases: 36 y 56, nuevo IC: 3.352941918440415\n",
      "Fusion de clases: 37 y 57, nuevo IC: 3.333653610310269\n",
      "Fusion de clases: 38 y 58, nuevo IC: 3.314365302180123\n",
      "Fusion de clases: 5 y 20, nuevo IC: 3.288212386502688\n",
      "Fusion de clases: 4 y 19, nuevo IC: 3.2689240783725424\n",
      "Fusion de clases: 3 y 18, nuevo IC: 3.244350435456896\n",
      "Fusion de clases: 2 y 8, nuevo IC: 3.214946075251606\n",
      "Fusion de clases: 25 y 43, nuevo IC: 3.185223976675493\n",
      "Fusion de clases: 39 y 42, nuevo IC: 3.1485003914270573\n",
      "Fusion de clases: 6 y 16, nuevo IC: 3.106491471393121\n",
      "Fusion de clases: 0 y 11, nuevo IC: 3.0629586578432004\n",
      "Fusion de clases: 34 y 40, nuevo IC: 3.0142659895077646\n",
      "Fusion de clases: 14 y 41, nuevo IC: 2.9835269458028297\n",
      "Fusion de clases: 32 y 51, nuevo IC: 2.9348342774673934\n",
      "Fusion de clases: 31 y 50, nuevo IC: 2.9008437892346035\n",
      "Fusion de clases: 5 y 17, nuevo IC: 2.8429788648441656\n",
      "Fusion de clases: 3 y 7, nuevo IC: 2.792951513009084\n",
      "Fusion de clases: 4 y 6, nuevo IC: 2.7383875697520446\n",
      "Fusion de clases: 33 y 39, nuevo IC: 2.6758051946938592\n",
      "Fusion de clases: 32 y 38, nuevo IC: 2.610894803510344\n",
      "Fusion de clases: 31 y 37, nuevo IC: 2.5574351479016184\n",
      "Fusion de clases: 30 y 36, nuevo IC: 2.515426227867682\n"
     ]
    }
   ],
   "source": [
    "bc.train(20,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a7563bd2-4397-47e2-b563-1df544baa536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['reservas', 'informe', 'ministerio'],\n",
       " 1: ['oro'],\n",
       " 2: ['divisas', 'comunic', 'establece'],\n",
       " 3: ['rusia', 'hoy', 'activos', 'valor', 'oficial', 'cada'],\n",
       " 4: ['subieron', 'mayo', 'eran', 'finanzas', 'depende', 'base'],\n",
       " 5: ['millones', 'estadounidenses', 'cambio'],\n",
       " 9: ['banco'],\n",
       " 10: ['central'],\n",
       " 14: ['pod', 'impide', 'empresa', 'ciudadano', 'fue'],\n",
       " 25: ['presidente', 'empleos', 'materia'],\n",
       " 26: ['generalitat', 'diversos', 'preven'],\n",
       " 27: ['jordi', 'sectores', 'siniestralidad'],\n",
       " 28: ['pujol'],\n",
       " 29: ['cree', 'necesidad', 'puede'],\n",
       " 30: ['necesario', 'falta', 'medida', 'sindicatos', 'tarde'],\n",
       " 31: ['gobierno', 'mano', 'legal', 'cena', 'administraciones', 'ocho', 'd'],\n",
       " 32: ['permisos',\n",
       "  'obra',\n",
       "  'durante',\n",
       "  'organizada',\n",
       "  'normativa',\n",
       "  'meses',\n",
       "  'permiso'],\n",
       " 33: ['residencia', 'departamento', 'cubr', 'anoche', 'laboral', 'freno'],\n",
       " 34: ['inmigrantes', 'trabajo', 'patronal', 'crecimiento'],\n",
       " 35: ['respond', 'empresarios', 'momento']}"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.get_words_by_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "b20ccf4c-1fda-4ebd-a3f1-f628ad3cf7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bc.vocab_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "10f0b7fb-57bb-432e-aa55-19cc001054dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5,\n",
       " 1: 4,\n",
       " 2: 5,\n",
       " 3: 6,\n",
       " 4: 7,\n",
       " 5: 6,\n",
       " 9: 4,\n",
       " 10: 4,\n",
       " 14: 6,\n",
       " 25: 4,\n",
       " 26: 3,\n",
       " 27: 3,\n",
       " 28: 3,\n",
       " 29: 3,\n",
       " 30: 6,\n",
       " 31: 8,\n",
       " 32: 8,\n",
       " 33: 7,\n",
       " 34: 5,\n",
       " 35: 3}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.c_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc0d7d-d25e-415f-9e1e-92177e5c8de3",
   "metadata": {},
   "source": [
    "# Latent semantic analysis (LSA) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d10d6d4d-7adf-4767-87a6-da29926a6166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "class LSA:\n",
    "    def __init__(self, documents: list, k:int):\n",
    "        # Almacenamos los documentos (oraciones)\n",
    "        self.documents = documents\n",
    "        # Almacenamos el numero de dimension final (reduccion)\n",
    "        self.k = k\n",
    "        # Generamos la matriz termino-documento\n",
    "        self.matrix = self.get_matrix_t_d(self.documents)\n",
    "        # Generamos el dataframe resumen\n",
    "        self.df_matrix = self.get_dataframe(self.matrix)\n",
    "        # Descomponemos en valores singulares\n",
    "        self.svd_k = self.get_SVD_k(self.matrix, k )\n",
    "\n",
    "    def get_SVD_k( self, matrix, k ):\n",
    "        U,S,VT = np.linalg.svd(matrix)\n",
    "        # U (mxr) S(rxr) V (nxr)\n",
    "        Sk = np.diag(S[:k]) # conveertimos a matriz diagonal\n",
    "        # Uk (mxk) Sk(kxk) Vk (nxk)\n",
    "        Uk, Vk = U[:,:k] , VT.T[:,:k]\n",
    "        return (Uk, Sk, Vk)        \n",
    "\n",
    "    def get_dataframe(self,matrix):\n",
    "        data = pd.DataFrame(matrix, index = self.list_terms , columns= range(1,len(self.documents)+1) )\n",
    "        return data\n",
    "        \n",
    "    def tokenize(self,text:str):\n",
    "        ''' Función que tokeniza un texto en sus palabras\n",
    "        '''\n",
    "        pattern=re.compile(r'\\b\\w+\\b')\n",
    "        return pattern.findall(text.lower())\n",
    "        \n",
    "\n",
    "    def get_terms(self, documents):\n",
    "        ''' Función que retorna un vocabulario de todos los terminos existentes\n",
    "            y sus frecuencias. [  V : {termino : freq} ]\n",
    "        '''\n",
    "        vocab_term = {}\n",
    "        # Recorremos cada documento u oracion\n",
    "        for text in documents:\n",
    "            # Tokenizamos el texto en palabras\n",
    "            text_tokenized = self.tokenize(text)\n",
    "            # Recorremos cada palabra del texto\n",
    "            for word in text_tokenized:\n",
    "                if word not in vocab_term:\n",
    "                    vocab_term[word] = 1\n",
    "                else:\n",
    "                    vocab_term[word] += 1\n",
    "        return vocab_term\n",
    "\n",
    "    def TF(self,i:int,j:int):\n",
    "        # Almacenamos el termino i del conjunto de terminos\n",
    "        termino_i = self.list_terms[i]\n",
    "        # Almacenamos el documento o oracion j \n",
    "        documento_j = self.documents[j]\n",
    "        # Tokenizamos el documento\n",
    "        doc_t = self.tokenize(documento_j)\n",
    "        # Contamos la frecuencia de la palabra en el documento\n",
    "        freq = 0\n",
    "        for word in doc_t:\n",
    "            if termino_i == word:\n",
    "                freq+=1\n",
    "        # Calculamos el TF\n",
    "        tf = freq/len(self.documents)\n",
    "        return tf      \n",
    "\n",
    "    def IDF(self,i:int):\n",
    "        ''' Calcula log(N/Nt)\n",
    "            N = el numero total de documentos\n",
    "            nt = el numero total de documentos que contiene el termino el termino i       \n",
    "        ''' \n",
    "        N = len(self.documents)\n",
    "        \n",
    "        # Almacenamos el termino i del conjunto de terminos\n",
    "        termino_i = self.list_terms[i]\n",
    "        nt = 0\n",
    "        for d in (self.documents):\n",
    "            d_tokenized = self.tokenize(d)\n",
    "            if termino_i in d_tokenized:\n",
    "                nt+=1\n",
    "        return math.log(N/nt)\n",
    "\n",
    "    def TF_IDF(self,i:int,j:int)->float:\n",
    "        TF = self.TF(i,j)\n",
    "        IDF = self.IDF(i)\n",
    "        return TF*IDF\n",
    "\n",
    "    def get_matrix_t_d(self,documents:list):\n",
    "        ''' Función que genera una matriz ( termino, documento )\n",
    "        '''\n",
    "        # Inicializamos el vocabulario de terminos\n",
    "        self.terms = self.get_terms(documents)\n",
    "        # Almacenamos la lista de terminos\n",
    "        self.list_terms = list(self.terms.keys())\n",
    "        # definimos el numero de filas(terminos)\n",
    "        m = len(self.terms)\n",
    "        # definimos el numero de columnas\n",
    "        n = len(documents)\n",
    "\n",
    "        # Inicializamos la matrix ( termino, documento )\n",
    "        matrix = np.zeros((m,n))\n",
    "        #print(matrix)\n",
    "\n",
    "        # Rellenamos la matriz\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                matrix[i][j] = self.TF_IDF(i,j)\n",
    "        return matrix\n",
    "\n",
    "    def similitud_terminos(self,i,j):\n",
    "        if isinstance(i,str) and isinstance(j,str):\n",
    "            i = self.list_terms.index(i)\n",
    "            j = self.list_terms.index(j)\n",
    "            \n",
    "        termino_i = self.list_terms[i] \n",
    "        termino_j = self.list_terms[j] \n",
    "        # Fila i de Uk\n",
    "        Uk , Sk , Vk = self.svd_k\n",
    "        ui = Uk[i,:] # (1,k) (k,k)\n",
    "        uj = Uk[j,:] # (1,k) (k,k)\n",
    "        s = np.dot((ui@Sk),(uj@Sk).T)\n",
    "        return s\n",
    "\n",
    "    def similitud_documentos(self,i,j):\n",
    "        i-=1\n",
    "        j-=1\n",
    "        documento_i = self.documents[i] \n",
    "        documento_j = self.documents[j] \n",
    "        # Fila i de (Vk (nxk))\n",
    "        Uk , Sk , Vk = self.svd_k\n",
    "        vi = Vk[i,:] # (1,k) (k,k)\n",
    "        vj = Vk[j,:] # (1,k) (k,k)\n",
    "        s = (vi@Sk)@(vj@Sk).T\n",
    "        return s\n",
    "\n",
    "    def similitud_t_d(self,i,j):\n",
    "        j-=1\n",
    "        if isinstance(i,str):\n",
    "            i = self.list_terms.index(i)\n",
    "        termino_i = self.list_terms[i] \n",
    "        documento_j = self.documents[j] \n",
    "\n",
    "        Uk , Sk , Vk = self.svd_k\n",
    "        ui = Uk[i,:] # (1,k) (k,k)\n",
    "        vj = Vk[j,:] # (1,k) (k,k)\n",
    "        s = (ui@Sk)@(vj@Sk).T\n",
    "        return s\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "987a02f1-a01d-42eb-bb0a-64ab41e31d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de documentos\n",
    "documents = [\n",
    "    \"La playa es calurosa y siempre se acostumbra a tomar un helado, llevar su traje de baño y nadar en el mar.\",\n",
    "    \"No me gusta ir a la playa, los helados son horribles y el mar es frío.\",\n",
    "    \"La noche es la mejor parte del día para estudiar sin problemas cualquier curso.\",\n",
    "    \"La universidad es un tanto complicada, más aún cuando sales a estudiar por las noches.\",\n",
    "    \"La brisa del mar me alegra el día y me relaja escuchar las olas.\",\n",
    "    \"La policía no hace nada por el país, no se siente seguridad en las calles.\",\n",
    "    \"La política requiere un cambio urgente para mejorar la calidad de vida de los ciudadanos.\",\n",
    "    \"Estudiar por la noche es más productivo, sin el ruido y distracciones del día.\",\n",
    "    \"Ir a la playa en verano es una tradición familiar, siempre llevamos toallas, helados y protector solar.\",\n",
    "    \"La corrupción en la política está dañando las instituciones del país y afectando a la sociedad.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Crear una instancia de LSA\n",
    "lsa = LSA(documents, k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ba18208f-ff23-4c6b-9252-6f52345d7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "U , S , VT = np.linalg.svd(lsa.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a1ebc8eb-5e73-47b0-912e-c440e5bd23c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86054936 0.75316941 0.73147901 0.71061493 0.69221707 0.66901398\n",
      " 0.63077008 0.62223306 0.54618726 0.48005076]\n"
     ]
    }
   ],
   "source": [
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "68ad2189-eb8f-45ba-b35d-d38fb8af5564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>policía</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>familiar</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.102165</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.051083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>del</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nada</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>está</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productivo</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mejor</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siempre</th>\n",
       "      <td>0.160944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160944</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gusta</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>la</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seguridad</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noche</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siente</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1         2         3    4         5         6    7   \\\n",
       "policía     0.000000  0.000000  0.000000  0.0  0.000000  0.230259  0.0   \n",
       "familiar    0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "y           0.102165  0.051083  0.000000  0.0  0.051083  0.000000  0.0   \n",
       "del         0.000000  0.000000  0.091629  0.0  0.091629  0.000000  0.0   \n",
       "nada        0.000000  0.000000  0.000000  0.0  0.000000  0.230259  0.0   \n",
       "está        0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "productivo  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "mejor       0.000000  0.000000  0.230259  0.0  0.000000  0.000000  0.0   \n",
       "siempre     0.160944  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "gusta       0.000000  0.230259  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "la          0.000000  0.000000  0.000000  0.0  0.000000  0.000000  0.0   \n",
       "seguridad   0.000000  0.000000  0.000000  0.0  0.000000  0.230259  0.0   \n",
       "noche       0.000000  0.000000  0.160944  0.0  0.000000  0.000000  0.0   \n",
       "siente      0.000000  0.000000  0.000000  0.0  0.000000  0.230259  0.0   \n",
       "\n",
       "                  8         9         10  \n",
       "policía     0.000000  0.000000  0.000000  \n",
       "familiar    0.000000  0.230259  0.000000  \n",
       "y           0.051083  0.051083  0.051083  \n",
       "del         0.091629  0.000000  0.091629  \n",
       "nada        0.000000  0.000000  0.000000  \n",
       "está        0.000000  0.000000  0.230259  \n",
       "productivo  0.230259  0.000000  0.000000  \n",
       "mejor       0.000000  0.000000  0.000000  \n",
       "siempre     0.000000  0.160944  0.000000  \n",
       "gusta       0.000000  0.000000  0.000000  \n",
       "la          0.000000  0.000000  0.000000  \n",
       "seguridad   0.000000  0.000000  0.000000  \n",
       "noche       0.160944  0.000000  0.000000  \n",
       "siente      0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.df_matrix.sample(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "3e0203a0-c54e-4d01-b3a9-b63b46fa6a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos las palabras con mejores similitudes de terminos\n",
    "# target : \"mar\"\n",
    "\n",
    "s_t = {}\n",
    "for i in lsa.list_terms:\n",
    "    s_t[\"mar - \"+i] = lsa.similitud_terminos(\"mar\",i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4aaf5e05-0137-40f9-b4fa-d1702c4c6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_s_t = sorted(s_t.items(),key = lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "8cc90cc6-4ca5-4aa2-baac-3f5b2f1a6de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mar - siempre: 0.026521398795850294\n",
      "mar - playa: 0.025440720357827473\n",
      "mar - de: 0.0235562076827481\n",
      "mar - se: 0.02317330031783334\n",
      "mar - calurosa: 0.022690179099762956\n"
     ]
    }
   ],
   "source": [
    "for term,similitud in ord_s_t[:5]:\n",
    "    print(f'{term}: {similitud}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ee6afdf1-feab-4643-bfde-d1af606ee664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función para probar para cualquier target\n",
    "def get_top_similitud(target,k):\n",
    "    s_t = {}\n",
    "    for i in lsa.list_terms:\n",
    "        s_t[f\"{target} - \"+i] = lsa.similitud_terminos(target,i)\n",
    "    ord_s_t = sorted(s_t.items(),key = lambda x:x[1],reverse=True)\n",
    "    for term,similitud in ord_s_t[:k]:\n",
    "        print(f'{term}: {similitud}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f5f73914-6b1d-4b2b-aab3-24b0079d002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policía - no: 0.044790142536814105\n",
      "policía - policía: 0.026677562268453307\n",
      "policía - hace: 0.026677562268453307\n",
      "policía - nada: 0.026677562268453307\n",
      "policía - siente: 0.026677562268453307\n",
      "policía - seguridad: 0.026677562268453307\n"
     ]
    }
   ],
   "source": [
    "get_top_similitud(\"policía\",6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "2ee92457-6b13-4390-86c9-3c494b0e51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos la similitud entre el primer documento y los demas\n",
    "s = {}\n",
    "for i in range(2,len(lsa.documents)+1):\n",
    "    s[i]= lsa.similitud_documentos(1,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "388ca90d-596e-4c89-bcf5-5da66e754571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer documento: La playa es calurosa y siempre se acostumbra a tomar un helado, llevar su traje de baño y nadar en el mar.\n"
     ]
    }
   ],
   "source": [
    "print(f'Primer documento: {lsa.documents[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d22e702f-ae6b-4b83-9386-4b6dca379e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_s = sorted( s.items(), key=lambda x: x[1] , reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "8f27fea3-cdeb-49d0-b5d0-380ccd4a3d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 9 -Valor similitud: 0.23715851141961342\n",
      "\tIr a la playa en verano es una tradición familiar, siempre llevamos toallas, helados y protector solar.\n",
      "\n",
      "Documento 7 -Valor similitud: 0.20603307768363885\n",
      "\tLa política requiere un cambio urgente para mejorar la calidad de vida de los ciudadanos.\n",
      "\n",
      "Documento 2 -Valor similitud: 0.11910083533187499\n",
      "\tNo me gusta ir a la playa, los helados son horribles y el mar es frío.\n",
      "\n",
      "Documento 5 -Valor similitud: 0.034728101977897906\n",
      "\tLa brisa del mar me alegra el día y me relaja escuchar las olas.\n",
      "\n",
      "Documento 10 -Valor similitud: 0.031070297171169825\n",
      "\tLa corrupción en la política está dañando las instituciones del país y afectando a la sociedad.\n",
      "\n",
      "Documento 6 -Valor similitud: 0.013310438583593584\n",
      "\tLa policía no hace nada por el país, no se siente seguridad en las calles.\n",
      "\n",
      "Documento 4 -Valor similitud: 0.007223818534109153\n",
      "\tLa universidad es un tanto complicada, más aún cuando sales a estudiar por las noches.\n",
      "\n",
      "Documento 8 -Valor similitud: -0.00012035880791517323\n",
      "\tEstudiar por la noche es más productivo, sin el ruido y distracciones del día.\n",
      "\n",
      "Documento 3 -Valor similitud: -0.001802418114973732\n",
      "\tLa noche es la mejor parte del día para estudiar sin problemas cualquier curso.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,similitud in ord_s :\n",
    "    print(f'Documento {i} -Valor similitud: {similitud}\\n\\t{lsa.documents[i-1]}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b93416-cf85-4d2d-aa85-28c493d5c0ac",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8a2f3-33e3-4cf4-af0b-c392e483bbc1",
   "metadata": {},
   "source": [
    "## Entrenamiento de un Modelo CBOW (Continuous Bag of Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca6db1c-aadd-4e2b-8a9f-9547a062aec3",
   "metadata": {},
   "source": [
    "El modelo CBOW (Continuous Bag of Words) es un modelo de lenguaje utilizado en procesamiento de lenguaje natural (NLP) para aprender representaciones vectoriales de palabras, conocido como \"embeddings\". En CBOW, el objetivo es predecir una palabra objetivo (target) a partir de su contexto (las palabras vecinas). Este modelo es particularmente útil para capturar relaciones semánticas entre palabras.\n",
    "\n",
    "### Funcionamiento Básico\n",
    "En CBOW, el contexto de una palabra es representado por las palabras adyacentes. El modelo intenta predecir la palabra objetivo utilizando la **media de los embeddings** de las palabras de su contexto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7610bb6e-9a5e-446f-900a-5c28a411640f",
   "metadata": {},
   "source": [
    "#### Definición de las Matrices de Pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80efda0-39c8-4ea7-9d59-68cd29a2e8ac",
   "metadata": {},
   "source": [
    "CBOW usa dos matrices de pesos:\n",
    "\n",
    "- $ W1_{(vocab-size, embedding-dim)}$: Representa el mapeo de palabras del vocabulario al espacio de embeddings.\n",
    "- $ W2_{(embedding-dim,vocab-size)}$: Proyecta los embeddings al **espacio de salida**, es decir, el vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b8038e2-941c-4811-9bc1-f148963af1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Configuración del vocabulario \n",
    "vocab = [\"comida\", \"saludable\", \"fruta\", \"vegetal\", \"ejercicio\", \"dieta\"]\n",
    "\n",
    "# Definición del tamaño del vocabulario y la dimensión del embedding\n",
    "vocab_size = len(vocab) # Tamaño del vocabulario (número de palabras distintas)\n",
    "embedding_dim = 3  # Dimensión del espacio de embedding\n",
    "\n",
    "\n",
    "# Inicialización aleatoria de las matrices de pesos\n",
    "W1 = np.random.rand(vocab_size, embedding_dim)\n",
    "W2 = np.random.rand(embedding_dim, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f64218ae-bd46-4671-a221-e98cecbe75ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47447791 0.07320595 0.21488767]\n",
      " [0.18179717 0.39568589 0.45661862]\n",
      " [0.49780696 0.38429341 0.57722565]\n",
      " [0.47247498 0.2618506  0.33040856]\n",
      " [0.98255717 0.56136288 0.56939379]\n",
      " [0.64397871 0.61475484 0.55014181]]\n"
     ]
    }
   ],
   "source": [
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "328c740e-591b-43f8-9d2c-675181d03b08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44284935 0.72053362 0.84686077 0.93479358 0.34808137 0.67055097]\n",
      " [0.4859237  0.40478613 0.52593498 0.29269393 0.71861158 0.18909701]\n",
      " [0.2277968  0.82732985 0.60364383 0.73194855 0.04315044 0.52752363]]\n"
     ]
    }
   ],
   "source": [
    "print(W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd809a5f-5e1b-4b89-b682-8f867b63a311",
   "metadata": {},
   "source": [
    "### Definir el contexto y la palabra objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "851f5619-2a19-49bd-b1a5-7c2531b36504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el contexto y la palabra objetivo\n",
    "context = [\"comida\", \"saludable\", \"fruta\"]\n",
    "target_word = \"dieta\"\n",
    "\n",
    "# Función para obtener el índice de una palabra en el vocabulario\n",
    "def word_to_index(word):\n",
    "    return vocab.index(word)\n",
    "\n",
    "# Función para convertir palabras a sus embeddings\n",
    "def get_context_embeddings(context_words):\n",
    "    context_indices = [word_to_index(word) for word in context_words]\n",
    "    return np.mean(W1[context_indices], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ae4bb-f1a0-408d-b884-e2a418fb089b",
   "metadata": {},
   "source": [
    "En este paso, calculamos el promedio de los embeddings de las palabras de contexto para generar la representación del contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ceb6a64-33ca-4ad4-a5f9-25e5cf2a5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding del contexto: [0.38469401 0.28439508 0.41624398]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Calcular el embedding promedio del contexto\n",
    "context_embedding = get_context_embeddings(context)\n",
    "print(\"Embedding del contexto:\", context_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9fb1f-b2d0-4c9b-ba08-086e0b7f6b0f",
   "metadata": {},
   "source": [
    "#### Función de activación softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630c596-1748-4ded-afe6-4613b042363f",
   "metadata": {},
   "source": [
    "Usaremos la función softmax para convertir la salida en una distribución de probabilidad sobre las palabras del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "615fa1be-d796-47ac-bb0d-90bb5e641eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción de la palabra objetivo (probabilidades): [0.13739304 0.19174111 0.18982252 0.1938317  0.1310667  0.15614493]\n"
     ]
    }
   ],
   "source": [
    "# Función softmax\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # estabilidad numérica\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "# Cálculo de la predicción\n",
    "output_layer = np.dot(context_embedding, W2)\n",
    "y_hat = softmax(output_layer)\n",
    "print(\"Predicción de la palabra objetivo (probabilidades):\", y_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d48d124-e503-49dc-a4ee-8d4871b5b0f9",
   "metadata": {},
   "source": [
    "### Calcular el Error y Realizar Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e706b4-a904-4c61-8f4b-a951c0ab84a6",
   "metadata": {},
   "source": [
    " calculamos el error entre la predicción y el valor real. Luego, aplicamos el algoritmo de backpropagation para actualizar las matrices de peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1819b305-05c8-4488-b7f6-3d3c3c202662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [ 0.13739304  0.19174111  0.18982252  0.1938317   0.1310667  -0.84385507]\n"
     ]
    }
   ],
   "source": [
    "# Codificación one-hot de la palabra objetivo\n",
    "target_index = word_to_index(target_word)\n",
    "y_true = np.zeros(vocab_size)\n",
    "y_true[target_index] = 1\n",
    "\n",
    "# Cálculo del error\n",
    "error = y_hat - y_true\n",
    "print(\"Error:\", error)\n",
    "\n",
    "# Calcular los gradientes para backpropagation\n",
    "learning_rate = 0.01\n",
    "dW2 = np.outer(context_embedding, error)\n",
    "dW1 = np.dot(error, W2.T) / len(context)\n",
    "\n",
    "# Actualizar matrices de peso\n",
    "W2 -= learning_rate * dW2\n",
    "for word in context:\n",
    "    W1[word_to_index(word)] -= learning_rate * dW1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105fa8c4-c67b-41c9-9592-0c2ee9007988",
   "metadata": {},
   "source": [
    "### Implementación de Múltiples Épocas (Clase CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01cd5eef-c3ea-40e7-b9c1-a3cb980de877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "class CBOW:\n",
    "    def __init__(self, path_corpus: str, embedding_dim=10, learning_rate=0.01, window_size=2):\n",
    "        # Configuración del modelo\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # Cargar y tokenizar el corpus\n",
    "        self.path_corpus = path_corpus\n",
    "        self.corpus = self.lectura_corpus(self.path_corpus)\n",
    "        self.corpus_tokenized = self.tokenizer(self.corpus)\n",
    "\n",
    "        # Construcción del vocabulario y frecuencias de unigramas\n",
    "        self.vocab_freq = self.get_unigrams(self.corpus_tokenized)\n",
    "        self.vocab_size = len(self.vocab_freq)\n",
    "        \n",
    "        # Inicialización de matrices de pesos\n",
    "        self.W1 = np.random.rand(self.vocab_size, self.embedding_dim)\n",
    "        self.W2 = np.random.rand(self.embedding_dim, self.vocab_size)\n",
    "\n",
    "    def lectura_corpus(self, path):\n",
    "        # Leer el archivo de texto\n",
    "        with open(path, mode='r', encoding='utf-8') as f:\n",
    "            text = f.read().lower()\n",
    "        return text\n",
    "\n",
    "    def tokenizer(self, corpus: str) -> list:\n",
    "        # Tokenización manual por palabras, eliminando puntuación\n",
    "        pattern = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "        return pattern.findall(corpus)\n",
    "\n",
    "    def get_unigrams(self, corpus: list):\n",
    "        # Crear el vocabulario y calcular frecuencia de unigramas\n",
    "        unigrams = {}\n",
    "        for word in corpus:\n",
    "            if word not in unigrams:\n",
    "                unigrams[word] = len(unigrams)  # Asignar un índice único a cada palabra\n",
    "        return unigrams\n",
    "\n",
    "    def generate_training_data(self):\n",
    "        # Generar pares (contexto, objetivo) para entrenamiento\n",
    "        data = []\n",
    "        for i in range(self.window_size, len(self.corpus_tokenized) - self.window_size):\n",
    "            context = self.corpus_tokenized[i - self.window_size:i] + self.corpus_tokenized[i + 1:i + 1 + self.window_size]\n",
    "            target = self.corpus_tokenized[i]\n",
    "            data.append((context, target))\n",
    "        return data\n",
    "\n",
    "    def word_to_index(self, word):\n",
    "        # Obtener el índice de una palabra en el vocabulario\n",
    "        return self.vocab_freq.get(word, -1)\n",
    "\n",
    "    def train(self, epochs=10):\n",
    "        # Generar datos de entrenamiento\n",
    "        training_data = self.generate_training_data()\n",
    "\n",
    "        # Entrenamiento del modelo\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for context_words, target_word in training_data:\n",
    "                # Forward pass\n",
    "                context_indices = [self.word_to_index(word) for word in context_words]\n",
    "                context_embedding = np.mean([self.W1[idx] for idx in context_indices if idx != -1], axis=0)\n",
    "                \n",
    "                # Predicción con softmax\n",
    "                output_layer = np.dot(context_embedding, self.W2)\n",
    "                y_hat = self.softmax(output_layer)\n",
    "\n",
    "                # Calcular el error y retropropagar\n",
    "                target_index = self.word_to_index(target_word)\n",
    "                if target_index == -1:\n",
    "                    continue  # Saltar si la palabra objetivo no está en el vocabulario\n",
    "                y_true = np.zeros(self.vocab_size)\n",
    "                y_true[target_index] = 1\n",
    "                error = y_hat - y_true\n",
    "                total_loss += -np.log(y_hat[target_index])\n",
    "\n",
    "                # Calcular gradientes\n",
    "                dW2 = np.outer(context_embedding, error)\n",
    "                dW1 = np.dot(error, self.W2.T) / len(context_words)\n",
    "\n",
    "                # Actualizar pesos\n",
    "                self.W2 -= self.learning_rate * dW2\n",
    "                for idx in context_indices:\n",
    "                    if idx != -1:\n",
    "                        self.W1[idx] -= self.learning_rate * dW1\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Pérdida total: {total_loss}\")\n",
    "\n",
    "    def softmax(self, x):\n",
    "        # Función softmax para convertir en probabilidades\n",
    "        exp_x = np.exp(x - np.max(x))  # Estabilidad numérica\n",
    "        return exp_x / exp_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f5e76b1-674a-4f9f-965f-c4021eabbd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Pérdida total: 1169647.5467188542\n",
      "Epoch 2, Pérdida total: 1136763.6994282864\n",
      "Epoch 3, Pérdida total: 1131022.8828293495\n",
      "Epoch 4, Pérdida total: 1127953.7253074294\n",
      "Epoch 5, Pérdida total: 1125473.787529957\n",
      "Epoch 6, Pérdida total: 1123180.657998894\n",
      "Epoch 7, Pérdida total: 1120930.7515392546\n",
      "Epoch 8, Pérdida total: 1118649.3266945228\n",
      "Epoch 9, Pérdida total: 1116246.2878479958\n",
      "Epoch 10, Pérdida total: 1113687.1420018906\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia del modelo CBOW\n",
    "model = CBOW(path_corpus='./corpus_preprocesado.txt', embedding_dim=10, learning_rate=0.01, window_size=2)\n",
    "\n",
    "# Entrenar el modelo con 10 épocas\n",
    "model.train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77e54353-30fa-4f20-9add-6cf896fe2a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91570967, 0.47086733, 0.11068263, 0.94227287, 0.66897521,\n",
       "       0.38132738, 0.30884651, 0.29975432, 0.47156777, 0.15490389])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.W1[model.word_to_index(\"perro\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1874c02d-f59a-499f-b645-76c510f19dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reservas', 0),\n",
       " ('oro', 1),\n",
       " ('divisas', 2),\n",
       " ('rusia', 3),\n",
       " ('subieron', 4),\n",
       " ('millones', 5),\n",
       " ('mayo', 6),\n",
       " ('hoy', 7),\n",
       " ('comunic', 8),\n",
       " ('banco', 9)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(model.vocab_freq.items(),key=lambda x: x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0fe95a2-a54e-4fa6-a298-32b78f7f41b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de la palabra 'banco': [ 0.77193698  0.59217798  1.26237157  0.76121653  0.66074864  0.58153191\n",
      "  0.3359068   0.42175322 -0.01057051  0.1800092 ]\n",
      "Embedding de la palabra 'finanzas': [ 0.67061719  0.61662113  0.97395911  0.91765037  0.51880896 -0.01679542\n",
      "  0.64156136 -0.0878074   0.87898887  0.3380141 ]\n",
      "Embedding de la palabra 'valor': [0.13874374 0.96748415 0.58792378 0.80494675 0.57097875 0.73314111\n",
      " 0.29649246 1.19444946 0.18205109 0.79156565]\n",
      "Embedding de la palabra 'presidente': [ 1.6986896   1.24095077  1.63291754  0.23428961 -0.53429421  0.65251895\n",
      " -0.15359939 -0.47328901 -0.92867692  0.11167905]\n",
      "Embedding de la palabra 'ciudadano': [0.68927727 0.85132164 0.28179425 1.05463194 0.73001378 0.71066437\n",
      " 0.60975327 0.11238979 0.69060419 0.81116487]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los embeddings de varias palabras en el vocabulario\n",
    "for word in ['banco', 'finanzas', 'valor', 'presidente', 'ciudadano']:\n",
    "    if word in model.vocab_freq:\n",
    "        idx = model.word_to_index(word)\n",
    "        print(f\"Embedding de la palabra '{word}': {model.W1[idx]}\")\n",
    "    else:\n",
    "        print(f\"La palabra '{word}' no está en el vocabulario.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51765985-f057-4170-bed8-69687351445d",
   "metadata": {},
   "source": [
    "### Reduciendo la Dimensionalidad con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f84e5a0c-d294-422f-b9dc-bfc51b9b2596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_embeddings(model, words):\n",
    "    # Obtener los embeddings de las palabras\n",
    "    embeddings = np.array([model.W1[model.word_to_index(word)] for word in words if word in model.vocab_freq])\n",
    "    words = [word for word in words if word in model.vocab_freq]\n",
    "\n",
    "    # Reducir a 2 dimensiones con PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    # Graficar\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, word in enumerate(words):\n",
    "        plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1])\n",
    "        plt.annotate(word, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]))\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"Visualización de Embeddings usando PCA\")\n",
    "    plt.show()\n",
    "\n",
    "# Palabras para visualizar\n",
    "words_to_plot = ['banco', 'finanzas', 'valor', 'presidente', 'ciudadano','millones','divisas']\n",
    "plot_embeddings(model, words_to_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c1f43-b21f-4503-9202-b7a66af9f89c",
   "metadata": {},
   "source": [
    "### Skip Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de33de-d591-4273-a062-65c7197d44c9",
   "metadata": {},
   "source": [
    "## Implementación del Algoritmo Skip-gram con Muestreo Negativo\n",
    "\n",
    "El modelo **Skip-gram** es un tipo de modelo de lenguaje utilizado para representar palabras en un espacio de embeddings. En lugar de predecir la palabra objetivo a partir de su contexto (como en CBOW), Skip-gram toma una palabra central y trata de predecir sus palabras de contexto. Esta técnica es útil para capturar relaciones semánticas entre palabras, y es una de las arquitecturas de **Word2Vec**.\n",
    "\n",
    "En este notebook, implementaremos el modelo Skip-gram con muestreo negativo para reducir el costo computacional, probaremos el entrenamiento en varios lotes y visualizaremos los resultados para analizar la calidad de los embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e4034a-a698-4f8d-ba31-d3f1e1a5eafc",
   "metadata": {},
   "source": [
    "### Diferencias entre Skip-gram y CBOW\n",
    "\n",
    "1. **Objetivo de Predicción**:\n",
    "   - **CBOW**: Dado un conjunto de palabras de contexto, predice la palabra objetivo (central).\n",
    "   - **Skip-gram**: Dada la palabra objetivo, predice cada palabra en su contexto.\n",
    "  \n",
    "2. **Uso de Muestreo Negativo**:\n",
    "   - En Skip-gram, el muestreo negativo se utiliza para reducir el costo de cálculo en la predicción de múltiples palabras de contexto. Este método crea ejemplos negativos (palabras que no deberían estar en el contexto) para reducir la probabilidad de ruido en el aprendizaje.\n",
    "  \n",
    "3. **Arquitectura del Modelo**:\n",
    "   - Ambos modelos utilizan dos matrices de embeddings (entrada y salida), pero en Skip-gram, el modelo trata de aprender una representación para predecir palabras de contexto a partir de una palabra central, lo cual ayuda a capturar relaciones entre palabras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d56f7-21e7-46a1-933a-b859b966c112",
   "metadata": {},
   "source": [
    "## Paso 1: Inicialización del Vocabulario y los Pesos\n",
    "\n",
    "Comenzamos creando una función para inicializar el vocabulario y definir las matrices de peso (`W1` y `W2`). `W1` contendrá los embeddings de entrada, mientras que `W2` contendrá los embeddings de salida. Ambos se inicializan de manera aleatoria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "649caf7c-f6f2-4813-b1b7-f647edd702e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SkipGram:\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.W1 = np.random.rand(vocab_size, embedding_dim) - 0.5  # Embeddings de entrada\n",
    "        self.W2 = np.random.rand(embedding_dim, vocab_size) - 0.5  # Embeddings de salida\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734e82b-5966-4923-ba56-59d36337d2ec",
   "metadata": {},
   "source": [
    "## Paso 2: Implementación de la Función Softmax\n",
    "\n",
    "La función `softmax` convierte los valores de salida en probabilidades, que utilizaremos para hacer predicciones sobre las palabras de contexto en Skip-gram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be059a9c-706f-43eb-bb84-593cc9260f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # Para estabilidad numérica\n",
    "    return exp_x / np.sum(exp_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47243086-0dd7-479b-8865-521c7e081a11",
   "metadata": {},
   "source": [
    "## Paso 3: Cálculo del Error\n",
    "\n",
    "En este paso, implementamos el cálculo del error. Usaremos la entropía cruzada para medir la diferencia entre las probabilidades predichas y las verdaderas. \n",
    "En lugar de calcular el error sobre todas las palabras, usamos **muestreo negativo**, que consiste en elegir algunas palabras aleatorias como \"negativas\" que no deberían aparecer en el contexto de la palabra central.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b219b6e0-e558-4310-8199-f64c6bc79606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampling(vocab_size, positive_indices, num_neg_samples):\n",
    "    \"\"\"Genera índices de palabras de muestreo negativo que no están en el contexto.\"\"\"\n",
    "    negatives = []\n",
    "    while len(negatives) < num_neg_samples:\n",
    "        neg = np.random.randint(0, vocab_size)\n",
    "        if neg not in positive_indices:\n",
    "            negatives.append(neg)\n",
    "    return negatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01097be-5012-4a9b-af3b-94e7a4acb613",
   "metadata": {},
   "source": [
    "## Implementación Completa del Modelo Skip-gram con Muestreo Negativo\n",
    "\n",
    "La implementación de `train` incluye la actualización de los embeddings para la palabra objetivo y sus palabras de contexto, así como el muestreo negativo. Cada contexto verdadero incrementa la probabilidad de las palabras reales, mientras que el muestreo negativo reduce la probabilidad de palabras que no están en el contexto, optimizando así el cálculo de probabilidades y mejorando la eficiencia del entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17cc1072-9916-4943-9664-73f080b98c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "class SkipGram:\n",
    "    def __init__(self, path_corpus: str, embedding_dim=10, learning_rate=0.01, window_size=2):\n",
    "        # Configuración del modelo\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # Cargar y tokenizar el corpus\n",
    "        self.path_corpus = path_corpus\n",
    "        self.corpus = self.lectura_corpus(self.path_corpus)\n",
    "        self.corpus_tokenized = self.tokenizer(self.corpus)\n",
    "\n",
    "        # Construcción del vocabulario y frecuencias de unigramas\n",
    "        self.vocab_freq = self.get_unigrams(self.corpus_tokenized)\n",
    "        self.vocab_size = len(self.vocab_freq)\n",
    "        \n",
    "        # Inicialización de matrices de pesos\n",
    "        self.W1 = np.random.rand(self.vocab_size, self.embedding_dim) - 0.5  # Embeddings de entrada\n",
    "        self.W2 = np.random.rand(self.embedding_dim, self.vocab_size) - 0.5  # Embeddings de salida\n",
    "\n",
    "    def lectura_corpus(self, path):\n",
    "        # Leer el archivo de texto\n",
    "        with open(path, mode='r', encoding='utf-8') as f:\n",
    "            text = f.read().lower()\n",
    "        return text\n",
    "\n",
    "    def tokenizer(self, corpus: str) -> list:\n",
    "        # Tokenización manual por palabras, eliminando puntuación\n",
    "        pattern = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "        return pattern.findall(corpus)\n",
    "\n",
    "    def get_unigrams(self, corpus: list):\n",
    "        # Crear el vocabulario y calcular frecuencia de unigramas\n",
    "        unigrams = {}\n",
    "        for word in corpus:\n",
    "            if word not in unigrams:\n",
    "                unigrams[word] = len(unigrams)  # Asignar un índice único a cada palabra\n",
    "        return unigrams\n",
    "\n",
    "    def generate_training_data(self):\n",
    "        # Generar pares (objetivo, contexto) para entrenamiento de Skip-gram\n",
    "        data = []\n",
    "        for i in range(self.window_size, len(self.corpus_tokenized) - self.window_size):\n",
    "            target_word = self.corpus_tokenized[i]\n",
    "            target_idx = self.word_to_index(target_word)\n",
    "            context_indices = [\n",
    "                self.word_to_index(self.corpus_tokenized[j])\n",
    "                for j in range(i - self.window_size, i + self.window_size + 1)\n",
    "                if j != i and j >= 0 and j < len(self.corpus_tokenized)\n",
    "            ]\n",
    "            data.append((target_idx, context_indices))\n",
    "        return data\n",
    "\n",
    "    def word_to_index(self, word):\n",
    "        # Obtener el índice de una palabra en el vocabulario\n",
    "        return self.vocab_freq.get(word, -1)\n",
    "\n",
    "    def negative_sampling(self, positive_indices, num_neg_samples):\n",
    "        \"\"\"Genera índices de palabras de muestreo negativo que no están en el contexto.\"\"\"\n",
    "        negatives = []\n",
    "        while len(negatives) < num_neg_samples:\n",
    "            neg = np.random.randint(0, self.vocab_size)\n",
    "            if neg not in positive_indices:\n",
    "                negatives.append(neg)\n",
    "        return negatives\n",
    "\n",
    "    def train(self, epochs=10, num_neg_samples=5):\n",
    "        # Generar datos de entrenamiento\n",
    "        training_data = self.generate_training_data()\n",
    "\n",
    "        # Entrenamiento del modelo\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for target_idx, context_indices in training_data:\n",
    "                # Forward pass\n",
    "                h = self.W1[target_idx]\n",
    "                u = np.dot(h, self.W2)\n",
    "                y_pred = self.softmax(u)\n",
    "\n",
    "                # Muestreo negativo\n",
    "                neg_samples = self.negative_sampling(context_indices, num_neg_samples)\n",
    "\n",
    "                # Ajuste para palabras de contexto reales\n",
    "                EI = np.array(y_pred)\n",
    "                EI[context_indices] -= 1 / len(context_indices)\n",
    "\n",
    "                # Ajuste para muestras negativas\n",
    "                EI[neg_samples] += 1 / len(neg_samples)\n",
    "\n",
    "                # Calcular gradientes\n",
    "                dW2 = np.outer(h, EI)\n",
    "                dW1 = np.dot(self.W2, EI).reshape(self.W1[target_idx].shape)\n",
    "\n",
    "                # Actualización de pesos\n",
    "                self.W1[target_idx] -= self.learning_rate * dW1\n",
    "                self.W2 -= self.learning_rate * dW2\n",
    "\n",
    "                # Calcular pérdida para contexto y muestras negativas\n",
    "                true_loss = -np.sum(np.log(y_pred[context_indices]))\n",
    "                neg_loss = -np.sum(np.log(1 - y_pred[neg_samples]))\n",
    "                total_loss += true_loss + neg_loss\n",
    "\n",
    "            print(f\"Epoch {epoch+1}, Pérdida total: {total_loss}\")\n",
    "\n",
    "    def softmax(self, x):\n",
    "        # Función softmax para convertir en probabilidades\n",
    "        exp_x = np.exp(x - np.max(x))  # Estabilidad numérica\n",
    "        return exp_x / exp_x.sum()\n",
    "\n",
    "    def word_vector(self, word):\n",
    "        # Obtener el embedding de una palabra\n",
    "        word_idx = self.word_to_index(word)\n",
    "        if word_idx != -1:\n",
    "            return self.W1[word_idx]\n",
    "        else:\n",
    "            print(f\"La palabra '{word}' no está en el vocabulario.\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b73b0-fa0c-4858-b19f-a196763ed6fc",
   "metadata": {},
   "source": [
    "## Prueba de Entrenamiento en Lotes\n",
    "\n",
    "Entrenamos el modelo con varias palabras objetivo y contextos para probar el modelo Skip-gram y observar la convergencia. El modelo ajustará los embeddings de palabras de manera que las palabras semánticamente relacionadas estén más cercanas en el espacio de embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e78e978c-8849-4756-8121-2462e0b43395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Pérdida total: 4928807.538822726\n",
      "Epoch 2, Pérdida total: 4920008.250712222\n",
      "Epoch 3, Pérdida total: 4896185.552821751\n",
      "Epoch 4, Pérdida total: 4817943.536538239\n",
      "Epoch 5, Pérdida total: 4723116.283773021\n",
      "Epoch 6, Pérdida total: 4664800.990538778\n",
      "Epoch 7, Pérdida total: 4653753.013754979\n",
      "Epoch 8, Pérdida total: 4663131.544858498\n",
      "Epoch 9, Pérdida total: 4656000.004620834\n",
      "Epoch 10, Pérdida total: 4735756.445940593\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia del modelo SkipGram\n",
    "skipgram_model = SkipGram(path_corpus='./corpus_preprocesado.txt', embedding_dim=10, learning_rate=0.01, window_size=2)\n",
    "\n",
    "# Entrenar el modelo con 10 épocas\n",
    "skipgram_model.train(epochs=10, num_neg_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fb69039e-4965-4d1b-b073-918cfad08a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploteamos con la funcion anterior los embedings reduciendolos su dimensionalidad\n",
    "# Palabras para visualizar\n",
    "words_to_plot = ['banco', 'finanzas', 'valor', 'presidente', 'ciudadano', 'millones', 'divisas']\n",
    "plot_embeddings(skipgram_model, words_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1bfd41-a29c-4118-be68-deba160901bd",
   "metadata": {},
   "source": [
    "# Implementación del Algoritmo GloVe (Global Vectors for Word Representation)\n",
    "\n",
    "GloVe es un modelo de lenguaje que utiliza estadísticas globales de co-ocurrencia para aprender representaciones vectoriales de palabras (embeddings). A diferencia de modelos basados en contexto local como Skip-gram o CBOW, GloVe se basa en la **matriz de co-ocurrencia global** para capturar relaciones semánticas en el vocabulario.\n",
    "\n",
    "### Objetivos de GloVe\n",
    "El objetivo de GloVe es encontrar vectores de palabras `wi` y `wj` tales que el producto punto de sus embeddings (junto con términos de sesgo) represente el logaritmo de la frecuencia de co-ocurrencia de esas palabras.\n",
    "\n",
    "En este notebook, implementaremos el modelo GloVe paso a paso:\n",
    "1. Construcción de la matriz de co-ocurrencia.\n",
    "2. Inicialización de los vectores de palabras y términos de sesgo.\n",
    "3. Definición de la función de costo y cálculo de gradientes.\n",
    "4. Optimización mediante gradiente descendente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d357a68-2cd0-41f5-96aa-d1b29e2abcee",
   "metadata": {},
   "source": [
    "## Paso 1: Construcción de la Matriz de Co-ocurrencia\n",
    "\n",
    "La matriz de co-ocurrencia `X` es una matriz `V x V` (donde `V` es el tamaño del vocabulario), en la que cada entrada `X[i, j]` representa la frecuencia de co-ocurrencia entre las palabras `i` y `j` en una ventana de contexto determinada.\n",
    "\n",
    "Para construir esta matriz, recorreremos el corpus, y para cada palabra, contaremos las palabras que aparecen en su ventana de contexto.\n",
    "\n",
    "**Nota**: `window_size` define la cantidad de palabras alrededor de la palabra central que se considerarán en el contexto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4949b991-d820-4c55-8e17-958b85e2a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_cooccurrence_matrix(corpus, vocab, window_size=2):\n",
    "    \"\"\"Construye la matriz de co-ocurrencia a partir del corpus y el vocabulario.\"\"\"\n",
    "    vocab_size = len(vocab)\n",
    "    cooccurrence_matrix = np.zeros((vocab_size, vocab_size))\n",
    "\n",
    "    # Recorre cada palabra en el corpus y cuenta co-ocurrencias en su ventana de contexto\n",
    "    for i, word in enumerate(corpus):\n",
    "        word_idx = vocab[word]\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(corpus), i + window_size + 1)\n",
    "        for j in range(start, end):\n",
    "            if i != j:  # Ignorar la palabra central\n",
    "                context_word = corpus[j]\n",
    "                context_idx = vocab[context_word]\n",
    "                cooccurrence_matrix[word_idx, context_idx] += 1\n",
    "\n",
    "    return cooccurrence_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b49caa25-5f0a-401c-8568-bf2e73342ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de co-ocurrencia:\n",
      "[[0. 1. 0. 1. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 0. 0. 2.]\n",
      " [0. 0. 1. 0. 0. 0. 1.]\n",
      " [1. 1. 1. 1. 2. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de corpus y vocabulario\n",
    "corpus = [\"el\", \"gato\", \"come\", \"pescado\", \"y\", \"el\", \"ratón\", \"come\", \"queso\"]\n",
    "vocab = {word: i for i, word in enumerate(set(corpus))}\n",
    "\n",
    "# Construir la matriz de co-ocurrencia\n",
    "cooccurrence_matrix = build_cooccurrence_matrix(corpus, vocab, window_size=2)\n",
    "print(\"Matriz de co-ocurrencia:\")\n",
    "print(cooccurrence_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1e741-7482-49b9-9539-c57e2eeb1418",
   "metadata": {},
   "source": [
    "## Paso 2: Inicialización de Vectores y Sesgos\n",
    "\n",
    "Para cada palabra en el vocabulario, inicializamos un vector de embedding `wi` y un término de sesgo `bi`. De manera similar, cada palabra en el contexto tendrá su propio vector `wj` y sesgo `bj`.\n",
    "\n",
    "Los embeddings y sesgos se inicializan aleatoriamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e87bb4d2-8515-4d08-bb1a-e5f312684e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(vocab_size, embedding_dim):\n",
    "    \"\"\"Inicializa los embeddings y sesgos para cada palabra en el vocabulario.\"\"\"\n",
    "    W = np.random.rand(vocab_size, embedding_dim) - 0.5\n",
    "    W_tilde = np.random.rand(vocab_size, embedding_dim) - 0.5\n",
    "    b = np.random.rand(vocab_size) - 0.5\n",
    "    b_tilde = np.random.rand(vocab_size) - 0.5\n",
    "    return W, W_tilde, b, b_tilde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed22db-b597-4192-a111-ba72ee8294dc",
   "metadata": {},
   "source": [
    "## Paso 3: Definición de la Función de Costo\n",
    "\n",
    "La función de costo de GloVe minimiza el error cuadrático entre el producto de los embeddings y el logaritmo de la co-ocurrencia:\n",
    "\n",
    "\\[\n",
    "$J = \\sum_{i,j=1}^V f(X_{ij}) \\left( w_i^T \\tilde{w_j} + b_i + \\tilde{b_j} - \\log(X_{ij}) \\right)^2$\n",
    "\\]\n",
    "\n",
    "Donde `f(X_ij)` es una función de ponderación que ajusta el peso de cada par `(i, j)` basado en la frecuencia `X_ij`.\n",
    "\n",
    "Implementaremos también el cálculo de gradientes para actualizar los embeddings `W`, `W_tilde` y los sesgos `b`, `b_tilde`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e0822d99-480d-46d9-95ed-f291ab1b8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting_function(x, xmax=100, alpha=0.75):\n",
    "    \"\"\"Función de ponderación f(X_ij).\"\"\"\n",
    "    return (x / xmax) ** alpha if x < xmax else 1\n",
    "\n",
    "def compute_cost_and_gradients(W, W_tilde, b, b_tilde, X, vocab_size, embedding_dim):\n",
    "    \"\"\"Calcula el costo y los gradientes para actualizar los parámetros.\"\"\"\n",
    "    cost = 0\n",
    "    dW = np.zeros_like(W)\n",
    "    dW_tilde = np.zeros_like(W_tilde)\n",
    "    db = np.zeros(vocab_size)\n",
    "    db_tilde = np.zeros(vocab_size)\n",
    "\n",
    "    for i in range(vocab_size):\n",
    "        for j in range(vocab_size):\n",
    "            if X[i, j] > 0:\n",
    "                # Cálculo del error\n",
    "                log_Xij = np.log(X[i, j])\n",
    "                weight = weighting_function(X[i, j])\n",
    "                diff = np.dot(W[i], W_tilde[j]) + b[i] + b_tilde[j] - log_Xij\n",
    "                cost += weight * (diff ** 2)\n",
    "\n",
    "                # Gradientes\n",
    "                grad = 2 * weight * diff\n",
    "                dW[i] += grad * W_tilde[j]\n",
    "                dW_tilde[j] += grad * W[i]\n",
    "                db[i] += grad\n",
    "                db_tilde[j] += grad\n",
    "\n",
    "    return cost, dW, dW_tilde, db, db_tilde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7707d9e-2d8a-4d2c-bdef-bc97ca62936b",
   "metadata": {},
   "source": [
    "## Paso 4: Optimización mediante Gradiente Descendente\n",
    "\n",
    "Usamos los gradientes calculados para actualizar los parámetros `W`, `W_tilde`, `b` y `b_tilde`. Realizaremos iteraciones sobre los datos hasta que la función de costo converja o se alcance un número máximo de épocas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "61511087-ef09-468d-8177-f2ff77f26303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_glove(X, vocab_size, embedding_dim, epochs=100, learning_rate=0.01):\n",
    "    \"\"\"Entrena el modelo GloVe mediante gradiente descendente.\"\"\"\n",
    "    W, W_tilde, b, b_tilde = initialize_parameters(vocab_size, embedding_dim)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        cost, dW, dW_tilde, db, db_tilde = compute_cost_and_gradients(W, W_tilde, b, b_tilde, X, vocab_size, embedding_dim)\n",
    "\n",
    "        # Actualizar parámetros\n",
    "        W -= learning_rate * dW\n",
    "        W_tilde -= learning_rate * dW_tilde\n",
    "        b -= learning_rate * db\n",
    "        b_tilde -= learning_rate * db_tilde\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Costo: {cost:.4f}\")\n",
    "\n",
    "    return W, W_tilde, b, b_tilde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ce6ab4-5611-4da0-9055-e58bcb8d69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "class GloVe:\n",
    "    def __init__(self, path_corpus, embedding_dim=10, window_size=2, xmax=100, alpha=0.75):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.window_size = window_size\n",
    "        self.xmax = xmax\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Cargar y tokenizar el corpus\n",
    "        self.path_corpus = path_corpus\n",
    "        self.corpus = self.lectura_corpus(self.path_corpus)\n",
    "        self.corpus_tokenized = self.tokenizer(self.corpus)\n",
    "\n",
    "        # Construir vocabulario y matriz de co-ocurrencia\n",
    "        self.vocab = {word: i for i, word in enumerate(set(self.corpus_tokenized))}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.X = self.build_cooccurrence_matrix(self.corpus_tokenized, self.vocab, window_size)\n",
    "\n",
    "        # Inicializar vectores de palabras y términos de sesgo\n",
    "        self.W, self.W_tilde, self.b, self.b_tilde = self.initialize_parameters(self.vocab_size, embedding_dim)\n",
    "\n",
    "    def lectura_corpus(self, path):\n",
    "        # Leer el archivo de texto\n",
    "        with open(path, mode='r', encoding='utf-8') as f:\n",
    "            text = f.read().lower()\n",
    "        return text\n",
    "\n",
    "    def tokenizer(self, corpus):\n",
    "        # Tokenización manual por palabras, eliminando puntuación\n",
    "        pattern = re.compile(r'\\b[a-zA-Z]+\\b')\n",
    "        return pattern.findall(corpus)\n",
    "\n",
    "    def build_cooccurrence_matrix(self, corpus, vocab, window_size):\n",
    "        \"\"\"Construye la matriz de co-ocurrencia a partir del corpus y el vocabulario.\"\"\"\n",
    "        vocab_size = len(vocab)\n",
    "        cooccurrence_matrix = np.zeros((vocab_size, vocab_size))\n",
    "\n",
    "        # Recorre cada palabra en el corpus y cuenta co-ocurrencias en su ventana de contexto\n",
    "        for i, word in enumerate(corpus):\n",
    "            word_idx = vocab[word]\n",
    "            start = max(0, i - window_size)\n",
    "            end = min(len(corpus), i + window_size + 1)\n",
    "            for j in range(start, end):\n",
    "                if i != j:  # Ignorar la palabra central\n",
    "                    context_word = corpus[j]\n",
    "                    context_idx = vocab[context_word]\n",
    "                    cooccurrence_matrix[word_idx, context_idx] += 1\n",
    "\n",
    "        return cooccurrence_matrix\n",
    "\n",
    "    def initialize_parameters(self, vocab_size, embedding_dim):\n",
    "        \"\"\"Inicializa los embeddings y sesgos para cada palabra en el vocabulario.\"\"\"\n",
    "        W = np.random.rand(vocab_size, embedding_dim) - 0.5\n",
    "        W_tilde = np.random.rand(vocab_size, embedding_dim) - 0.5\n",
    "        b = np.random.rand(vocab_size) - 0.5\n",
    "        b_tilde = np.random.rand(vocab_size) - 0.5\n",
    "        return W, W_tilde, b, b_tilde\n",
    "\n",
    "    def weighting_function(self, x):\n",
    "        \"\"\"Función de ponderación f(X_ij).\"\"\"\n",
    "        return (x / self.xmax) ** self.alpha if x < self.xmax else 1\n",
    "\n",
    "    def compute_cost_and_gradients(self):\n",
    "        \"\"\"Calcula el costo y los gradientes para actualizar los parámetros.\"\"\"\n",
    "        cost = 0\n",
    "        dW = np.zeros_like(self.W)\n",
    "        dW_tilde = np.zeros_like(self.W_tilde)\n",
    "        db = np.zeros(self.vocab_size)\n",
    "        db_tilde = np.zeros(self.vocab_size)\n",
    "\n",
    "        for i in range(self.vocab_size):\n",
    "            for j in range(self.vocab_size):\n",
    "                if self.X[i, j] > 0:\n",
    "                    log_Xij = np.log(self.X[i, j])\n",
    "                    weight = self.weighting_function(self.X[i, j])\n",
    "                    diff = np.dot(self.W[i], self.W_tilde[j]) + self.b[i] + self.b_tilde[j] - log_Xij\n",
    "                    cost += weight * (diff ** 2)\n",
    "\n",
    "                    # Gradientes\n",
    "                    grad = 2 * weight * diff\n",
    "                    dW[i] += grad * self.W_tilde[j]\n",
    "                    dW_tilde[j] += grad * self.W[i]\n",
    "                    db[i] += grad\n",
    "                    db_tilde[j] += grad\n",
    "\n",
    "        return cost, dW, dW_tilde, db, db_tilde\n",
    "\n",
    "    def train(self, epochs=100, learning_rate=0.01):\n",
    "        \"\"\"Entrena el modelo GloVe mediante gradiente descendente.\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            cost, dW, dW_tilde, db, db_tilde = self.compute_cost_and_gradients()\n",
    "\n",
    "            # Actualización de parámetros\n",
    "            self.W -= learning_rate * dW\n",
    "            self.W_tilde -= learning_rate * dW_tilde\n",
    "            self.b -= learning_rate * db\n",
    "            self.b_tilde -= learning_rate * db_tilde\n",
    "\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}, Costo: {cost:.4f}\")\n",
    "\n",
    "    def get_embedding(self, word):\n",
    "        \"\"\"Obtiene el embedding de una palabra.\"\"\"\n",
    "        idx = self.vocab.get(word)\n",
    "        if idx is not None:\n",
    "            return self.W[idx]\n",
    "        else:\n",
    "            print(f\"La palabra '{word}' no está en el vocabulario.\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e766e9c-0e27-4a13-a779-ddff1cee60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Costo: 10327.7925\n",
      "Epoch 2, Costo: 7229.6658\n",
      "Epoch 3, Costo: 6498.9640\n",
      "Epoch 4, Costo: 6083.5970\n",
      "Epoch 5, Costo: 5792.4456\n",
      "Epoch 6, Costo: 5568.6863\n",
      "Epoch 7, Costo: 5387.4132\n",
      "Epoch 8, Costo: 5235.4551\n",
      "Epoch 9, Costo: 5104.9713\n",
      "Epoch 10, Costo: 4990.8930\n",
      "Epoch 11, Costo: 4889.7431\n",
      "Epoch 12, Costo: 4799.0295\n",
      "Epoch 13, Costo: 4716.9041\n",
      "Epoch 14, Costo: 4641.9573\n",
      "Epoch 15, Costo: 4573.0869\n",
      "Epoch 16, Costo: 4509.4116\n",
      "Epoch 17, Costo: 4450.2127\n",
      "Epoch 18, Costo: 4394.8937\n",
      "Epoch 19, Costo: 4342.9528\n",
      "Epoch 20, Costo: 4293.9635\n",
      "Epoch 21, Costo: 4247.5606\n",
      "Epoch 22, Costo: 4203.4303\n",
      "Epoch 23, Costo: 4161.3021\n",
      "Epoch 24, Costo: 4120.9428\n",
      "Epoch 25, Costo: 4082.1514\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia y entrenar el modelo GloVe\n",
    "glove_model = GloVe(path_corpus='./corpus_preprocesado.txt', embedding_dim=10, window_size=2)\n",
    "glove_model.train(epochs=25, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62fe017-14ab-41c9-9c34-90f91c150993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_embeddings(model, words):\n",
    "    # Obtener los embeddings de las palabras\n",
    "    embeddings = []\n",
    "    valid_words = []\n",
    "    for word in words:\n",
    "        embedding = model.get_embedding(word)\n",
    "        if embedding is not None:\n",
    "            embeddings.append(embedding)\n",
    "            valid_words.append(word)\n",
    "    \n",
    "    # Convertir a un array de numpy\n",
    "    embeddings = np.array(embeddings)\n",
    "    \n",
    "    # Reducir a 2 dimensiones con PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    # Graficar\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i, word in enumerate(valid_words):\n",
    "        plt.scatter(reduced_embeddings[i, 0], reduced_embeddings[i, 1])\n",
    "        plt.annotate(word, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]))\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"Visualización de Embeddings usando PCA\")\n",
    "    plt.show()\n",
    "\n",
    "# Palabras para visualizar\n",
    "words_to_plot = ['banco', 'finanzas', 'valor', 'presidente', 'ciudadano', 'millones', 'divisas']\n",
    "plot_embeddings(glove_model, words_to_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475065bf-b441-4829-973f-44547809a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ced7c-0d02-4e8e-8a4d-fdfafbf0638b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d0859-37d3-4ea7-b939-9de6aa2dd20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd174d8-3123-4c82-bf06-791464a6bdbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4825b-1d78-4f1d-a056-1e3770966063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6ff60-62b2-4dc2-9c03-1b89af286420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0f4c7-e62a-4d28-8ed1-d9ea3a46fe73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
